{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/QWXMLcNJ4Jo4iFHIRIQB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/springboardmentor3847a-cloud/AI-System-to-Automatically-Review-and-Summarize-Research-Papers-/blob/HarshithaNancharla-Branch/Milestone%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTFLZqw9-cxF",
        "outputId": "713fcd2e-d0d2-4e57-81ea-31c3680db6da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pymupdf4llm\n",
            "  Downloading pymupdf4llm-0.2.8-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from pymupdf4llm) (0.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf4llm-0.2.8-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf, pymupdf4llm\n",
            "Successfully installed pymupdf-1.26.7 pymupdf4llm-0.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf pymupdf4llm nltk scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folders = [\n",
        "    \"data/pdfs\",\n",
        "    \"data/extracted_text\",\n",
        "    \"data/structured_sections\",\n",
        "    \"data/comparisons\"\n",
        "]\n",
        "\n",
        "for folder in folders:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "print(\"Folder structure created ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMVwE1YX-fHG",
        "outputId": "0bc21c56-4ca8-4cb6-80bc-a1d6b6778689"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder structure created ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEMANTIC_SCHOLAR_API_KEY = \"OWZwvFDAAe9QXGhc0m66v2SWJgZ00c3CaZzDSLQq\"\n"
      ],
      "metadata": {
        "id": "Wpo35lSt-qAh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "headers = {\n",
        "    \"x-api-key\": SEMANTIC_SCHOLAR_API_KEY\n",
        "}\n",
        "\n",
        "query = \"fake news detection using machine learning\"\n",
        "url = f\"https://api.semanticscholar.org/graph/v1/paper/search?query={query}&limit=5&fields=title,openAccessPdf\"\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "papers = response.json()[\"data\"]\n",
        "\n",
        "for i, paper in enumerate(papers):\n",
        "    pdf_info = paper.get(\"openAccessPdf\")\n",
        "    if pdf_info and pdf_info.get(\"url\"):\n",
        "        pdf_url = pdf_info[\"url\"]\n",
        "        pdf_data = requests.get(pdf_url).content\n",
        "\n",
        "        file_path = f\"data/pdfs/paper_{i+1}.pdf\"\n",
        "        with open(file_path, \"wb\") as f:\n",
        "            f.write(pdf_data)\n",
        "\n",
        "        print(f\"Downloaded: {file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ1ePDOU_Gpq",
        "outputId": "58e3a78c-9f94-4f84-cfd2-9904f81785f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: data/pdfs/paper_4.pdf\n",
            "Downloaded: data/pdfs/paper_5.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "for pdf_file in os.listdir(\"data/pdfs\"):\n",
        "    pdf_path = f\"data/pdfs/{pdf_file}\"\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    with open(f\"data/extracted_text/{pdf_file}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "print(\"Text extracted from all PDFs ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B4jCdTc_LVx",
        "outputId": "3dc35f2b-0908-4aa5-877c-d194ff3e31c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extracted from all PDFs ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'Page \\d+', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "for file in os.listdir(\"data/extracted_text\"):\n",
        "    path = f\"data/extracted_text/{file}\"\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        cleaned = clean_text(f.read())\n",
        "\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(cleaned)\n",
        "\n",
        "print(\"Text cleaned ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-98Uncv_Zbv",
        "outputId": "6b903593-b88a-4d0b-e4bf-dcfe7db98f5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text cleaned ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sections(text):\n",
        "    sections = {\n",
        "        \"abstract\": \"\",\n",
        "        \"introduction\": \"\",\n",
        "        \"methodology\": \"\",\n",
        "        \"results\": \"\",\n",
        "        \"conclusion\": \"\"\n",
        "    }\n",
        "\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    for key in sections.keys():\n",
        "        if key in text_lower:\n",
        "            start = text_lower.find(key)\n",
        "            sections[key] = text[start:start+1500]\n",
        "\n",
        "    return sections\n"
      ],
      "metadata": {
        "id": "HLcwYxxW_khK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "for file in os.listdir(\"data/extracted_text\"):\n",
        "    with open(f\"data/extracted_text/{file}\", \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    sections = split_sections(text)\n",
        "\n",
        "    json_path = f\"data/structured_sections/{file}.json\"\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(sections, f, indent=4)\n",
        "\n",
        "print(\"Structured JSON created ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5Etd-au_pqu",
        "outputId": "93ed0796-da6c-4196-b982-4536d47e54c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structured JSON created ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def extract_key_sentences(text, num=3):\n",
        "    sentences = sent_tokenize(text)\n",
        "    return sentences[:num]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkgD_pGL_vfh",
        "outputId": "d11915df-8d0f-483b-c948-6fc63c54b12c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "texts = []\n",
        "\n",
        "for file in os.listdir(\"data/extracted_text\"):\n",
        "    with open(f\"data/extracted_text/{file}\", \"r\", encoding=\"utf-8\") as f:\n",
        "        texts.append(f.read())\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf = vectorizer.fit_transform(texts)\n",
        "similarity = cosine_similarity(tfidf)\n",
        "\n",
        "print(\"Similarity Matrix:\")\n",
        "print(similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZDGSl6I__X2",
        "outputId": "6bf9f24a-2436-4f62-9bfd-17857a1c035e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Matrix:\n",
            "[[1.         0.85077773]\n",
            " [0.85077773 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MEvJanMrAERc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}