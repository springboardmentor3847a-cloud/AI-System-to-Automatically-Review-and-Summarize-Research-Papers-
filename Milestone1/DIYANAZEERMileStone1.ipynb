{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO8y8yQrGaZd"
      },
      "source": [
        "MODULE 1: Topic Input & Paper Search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AxYM14tbGbeX",
        "outputId": "3eb20c60-ba23-49d6-ddf5-ddbbe09379ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "MODULE 1: TOPIC INPUT & PAPER SEARCH\n",
            "================================================================================\n",
            "\n",
            "Enter research topic: machine learning\n",
            "\n",
            "Searching for papers on: 'machine learning'\n",
            "Requesting 3 papers from Semantic Scholar...\n",
            "Using Semantic Scholar without API key (public access)\n",
            "Search complete!\n",
            "Total papers found: 3\n",
            "Papers with PDF available: 3\n",
            "Search results saved to: data/search_results/paper_search_results_machine_learning.json\n",
            "\n",
            "================================================================================\n",
            "SEARCH RESULTS: machine learning\n",
            "================================================================================\n",
            "\n",
            "1. Physics-informed machine learning\n",
            "   Year: 2021 | Citations: 4961\n",
            "   PDF Available: YES\n",
            "\n",
            "2. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\n",
            "   Year: 2017 | Citations: 9877\n",
            "   PDF Available: YES\n",
            "\n",
            "3. A Survey on Bias and Fairness in Machine Learning\n",
            "   Year: 2019 | Citations: 5120\n",
            "   PDF Available: YES\n",
            "\n",
            "Module 1 complete! Results saved to: data/search_results/paper_search_results_machine_learning.json\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# MODULE 1: Topic Input & Paper Search\n",
        "# ============================================\n",
        "\n",
        "import json\n",
        "import os\n",
        "from semanticscholar import SemanticScholar\n",
        "from datetime import datetime\n",
        "\n",
        "# ====================\n",
        "# 1. SETUP API KEY\n",
        "# ====================\n",
        "\n",
        "def setup_api_key():\n",
        "    sch = SemanticScholar()\n",
        "    print(\"Using Semantic Scholar without API key (public access)\")\n",
        "    return sch\n",
        "\n",
        "# ====================\n",
        "# 2. PAPER SEARCH\n",
        "# ====================\n",
        "\n",
        "def search_papers(topic, limit=3):\n",
        "    print(f\"\\nSearching for papers on: '{topic}'\")\n",
        "    print(f\"Requesting {limit} papers from Semantic Scholar...\")\n",
        "\n",
        "    sch = setup_api_key()\n",
        "\n",
        "    try:\n",
        "        results = sch.search_paper(query=topic)\n",
        "\n",
        "        papers = []\n",
        "        count = 0\n",
        "\n",
        "        for paper in results:\n",
        "            paper_data = {\n",
        "                \"title\": paper.title,\n",
        "                \"authors\": [a.name for a in paper.authors] if paper.authors else [],\n",
        "                \"year\": paper.year,\n",
        "                \"paperId\": paper.paperId,\n",
        "                \"abstract\": paper.abstract[:300] + \"...\" if paper.abstract else \"No abstract available\",\n",
        "                \"citationCount\": paper.citationCount,\n",
        "                \"venue\": paper.venue,\n",
        "                \"url\": paper.url,\n",
        "                \"pdf_url\": paper.openAccessPdf[\"url\"] if paper.openAccessPdf else None,\n",
        "                \"has_pdf\": bool(paper.openAccessPdf)\n",
        "            }\n",
        "            papers.append(paper_data)\n",
        "            count += 1\n",
        "            if count >= limit:\n",
        "                break\n",
        "\n",
        "        print(\"Search complete!\")\n",
        "        print(f\"Total papers found: {len(papers)}\")\n",
        "        print(f\"Papers with PDF available: {sum(1 for p in papers if p['has_pdf'])}\")\n",
        "\n",
        "        return {\n",
        "            \"topic\": topic,\n",
        "            \"search_timestamp\": datetime.now().isoformat(),\n",
        "            \"total_results\": len(papers),\n",
        "            \"papers_with_pdf\": sum(1 for p in papers if p[\"has_pdf\"]),\n",
        "            \"papers\": papers\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error searching papers: {e}\")\n",
        "        return None\n",
        "\n",
        "# ====================\n",
        "# 3. SAVE METADATA\n",
        "# ====================\n",
        "\n",
        "def save_search_results(data):\n",
        "    safe_topic = \"\".join(c for c in data[\"topic\"] if c.isalnum() or c == \" \").replace(\" \", \"_\")\n",
        "    filename = f\"paper_search_results_{safe_topic}.json\"\n",
        "\n",
        "    os.makedirs(\"data/search_results\", exist_ok=True)\n",
        "    filepath = os.path.join(\"data/search_results\", filename)\n",
        "\n",
        "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Search results saved to: {filepath}\")\n",
        "    return filepath\n",
        "\n",
        "# ====================\n",
        "# 4. DISPLAY RESULTS\n",
        "# ====================\n",
        "\n",
        "def display_search_results(data):\n",
        "    papers = data[\"papers\"]\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"SEARCH RESULTS: {data['topic']}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for i, paper in enumerate(papers):\n",
        "        print(f\"\\n{i+1}. {paper['title']}\")\n",
        "        print(f\"   Year: {paper['year']} | Citations: {paper['citationCount']}\")\n",
        "        print(f\"   PDF Available: {'YES' if paper['has_pdf'] else 'NO'}\")\n",
        "\n",
        "# ====================\n",
        "# 5. MAIN FUNCTION\n",
        "# ====================\n",
        "\n",
        "def main_search():\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"MODULE 1: TOPIC INPUT & PAPER SEARCH\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    topic = input(\"\\nEnter research topic: \").strip()\n",
        "    if not topic:\n",
        "        topic = \"data mining\"\n",
        "\n",
        "    results = search_papers(topic, limit=3)\n",
        "\n",
        "    if results:\n",
        "        save_path = save_search_results(results)\n",
        "        display_search_results(results)\n",
        "        print(f\"\\nModule 1 complete! Results saved to: {save_path}\")\n",
        "    else:\n",
        "        print(\"No results found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_search()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abeb2a58",
        "outputId": "ab0697ba-8910-4501-c9c7-bdeb27cbd031"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install semanticscholar python-dotenv"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: semanticscholar in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (from semanticscholar) (9.1.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from semanticscholar) (0.28.1)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from semanticscholar) (1.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->semanticscholar) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->semanticscholar) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->semanticscholar) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->semanticscholar) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->semanticscholar) (0.16.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->semanticscholar) (4.15.0)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}