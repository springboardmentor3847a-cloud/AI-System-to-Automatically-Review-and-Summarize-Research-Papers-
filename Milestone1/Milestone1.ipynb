{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LOwVbgg7Smz",
        "outputId": "8ddeb799-d917-4e56-f96e-c6b0b06db66c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.4/1.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a95xq8Lf7Qoi"
      },
      "outputs": [],
      "source": [
        "!pip install requests semanticscholar crossrefapi PyMuPDF -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from crossref.restful import Works\n",
        "from semanticscholar import SemanticScholar\n",
        "import fitz  # PyMuPDF\n"
      ],
      "metadata": {
        "id": "BYz7HOeQ8Cqg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîç 1. Search Semantic Scholar"
      ],
      "metadata": {
        "id": "bxyn7F27-H0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_semantic_scholar(query, max_results=10):\n",
        "    \"\"\"\n",
        "    Searches Semantic Scholar for research papers\n",
        "    based on a topic input.\n",
        "    Returns structured metadata for each paper.\n",
        "    \"\"\"\n",
        "    print(\"üîç Searching Semantic Scholar...\")\n",
        "    sch = SemanticScholar(timeout=10)\n",
        "\n",
        "    papers = []\n",
        "    try:\n",
        "        # Perform API search\n",
        "        results = sch.search_paper(query, limit=max_results)\n",
        "\n",
        "        # Extract fields from each paper\n",
        "        for p in results:\n",
        "            papers.append({\n",
        "                \"title\": p.title,\n",
        "                \"authors\": [a.name for a in p.authors] if p.authors else [],\n",
        "                \"year\": p.year,\n",
        "                \"pdf_url\": p.openAccessPdf.get(\"url\") if p.openAccessPdf else None,\n",
        "                \"citationCount\": p.citationCount,\n",
        "                \"abstract\": p.abstract,\n",
        "                \"url\": p.url\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(\"Semantic Scholar error:\", e)\n",
        "\n",
        "    return papers\n"
      ],
      "metadata": {
        "id": "P_w1YJvV8VNw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_semantic_scholar(query, max_results=10):\n",
        "    \"\"\"\n",
        "    Searches Semantic Scholar for research papers\n",
        "    based on a topic input.\n",
        "    Returns structured metadata for each paper.\n",
        "    \"\"\"\n",
        "    print(\"üîç Searching Semantic Scholar...\")\n",
        "    sch = SemanticScholar(timeout=10)\n",
        "\n",
        "    papers = []\n",
        "    try:\n",
        "        # Perform API search\n",
        "        results = sch.search_paper(query, limit=max_results)\n",
        "\n",
        "        # Extract fields from each paper\n",
        "        for p in results:\n",
        "            papers.append({\n",
        "                \"title\": p.title,\n",
        "                \"authors\": [a.name for a in p.authors] if p.authors else [],\n",
        "                \"year\": p.year,\n",
        "                \"pdf_url\": p.openAccessPdf.get(\"url\") if p.openAccessPdf else None,\n",
        "                \"citationCount\": p.citationCount,\n",
        "                \"abstract\": p.abstract,\n",
        "                \"url\": p.url\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(\"Semantic Scholar error:\", e)\n",
        "\n",
        "    return papers\n"
      ],
      "metadata": {
        "id": "4CVqDCSE8dfA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìö 2. Search CrossRef (Backup API)"
      ],
      "metadata": {
        "id": "R0njzwcK-MCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_crossref(query, max_results=5):\n",
        "    \"\"\"\n",
        "    Searches CrossRef as a fallback API source.\n",
        "    Useful when Semantic Scholar returns fewer results.\n",
        "    \"\"\"\n",
        "    print(\"üîç Searching CrossRef...\")\n",
        "    works = Works()\n",
        "    papers = []\n",
        "\n",
        "    try:\n",
        "        # Search CrossRef and sort by relevance (score)\n",
        "        results = works.query(query).sort(\"score\")\n",
        "\n",
        "        count = 0\n",
        "        for item in results:\n",
        "            if count >= max_results:\n",
        "                break\n",
        "\n",
        "            # Extract minimal metadata\n",
        "            papers.append({\n",
        "                \"title\": item.get(\"title\", [\"\"])[0],\n",
        "                \"authors\": [a.get(\"family\",\"\") for a in item.get(\"author\", [])],\n",
        "                \"year\": item.get(\"issued\", {}).get(\"date-parts\", [[None]])[0][0],\n",
        "                \"pdf_url\": None,            # CrossRef does not give PDFs\n",
        "                \"citationCount\": None,\n",
        "                \"abstract\": None,\n",
        "                \"url\": item.get(\"URL\", \"\")\n",
        "            })\n",
        "            count += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"CrossRef error:\", e)\n",
        "\n",
        "    return papers\n"
      ],
      "metadata": {
        "id": "TmM08zZN9eGX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† 3. Main Function ‚Äî Combine Both APIs & Save JSON"
      ],
      "metadata": {
        "id": "FxV4AoaH-TuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_module1(topic):\n",
        "    \"\"\"\n",
        "    Runs the full Module-1 workflow:\n",
        "    1. Search Semantic Scholar\n",
        "    2. Search CrossRef\n",
        "    3. Combine results\n",
        "    4. Save output to JSON\n",
        "    \"\"\"\n",
        "    print(\"\\n===============================\")\n",
        "    print(\"MODULE 1: Paper Search Started\")\n",
        "    print(\"===============================\\n\")\n",
        "\n",
        "    # API calls\n",
        "    ss_results = search_semantic_scholar(topic, max_results=10)\n",
        "    cr_results = search_crossref(topic, max_results=5)\n",
        "\n",
        "    # Merge results\n",
        "    all_papers = ss_results + cr_results\n",
        "\n",
        "    print(f\"\\nüìö Total papers found: {len(all_papers)}\")\n",
        "\n",
        "    # Create output folder\n",
        "    os.makedirs(\"data/search_results\", exist_ok=True)\n",
        "\n",
        "    # Dynamic filename\n",
        "    filename = f\"data/search_results/search_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "\n",
        "    # Save JSON data\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\n",
        "            \"topic\": topic,\n",
        "            \"papers\": all_papers\n",
        "        }, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(\"\\n‚úÖ Module 1 Completed!\")\n",
        "    print(f\"üìÅ Results saved to: {filename}\")\n",
        "\n",
        "    return filename\n"
      ],
      "metadata": {
        "id": "h5bZUoal9oSz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ñ∂ Run Module-1"
      ],
      "metadata": {
        "id": "-Rz5SXin-luf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"AI system to automatically review and summarize research papers\"\n",
        "run_module1(topic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "3VUSofrV-jP8",
        "outputId": "959a356e-c45e-4ed0-84d7-a2964decaccd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===============================\n",
            "MODULE 1: Paper Search Started\n",
            "===============================\n",
            "\n",
            "üîç Searching Semantic Scholar...\n",
            "üîç Searching CrossRef...\n",
            "\n",
            "üìö Total papers found: 16\n",
            "\n",
            "‚úÖ Module 1 Completed!\n",
            "üìÅ Results saved to: data/search_results/search_results_20251211_195444.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/search_results/search_results_20251211_195444.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß© MODULE 2 ‚Äî PDF Filtering, Ranking, Downloading\n",
        "Select PDFs ‚Üí Download with Verification ‚Üí Save Report"
      ],
      "metadata": {
        "id": "GveW_MQy-3WG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üì• 1. Load Search Results"
      ],
      "metadata": {
        "id": "QaMuP7Vi_Hu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_search_results(filepath=None):\n",
        "    \"\"\"\n",
        "    Loads the JSON file generated in Module-1.\n",
        "    \"\"\"\n",
        "    if not filepath:\n",
        "        print(\"‚ùå ERROR: Provide a valid filepath.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        print(f\" Loaded {len(data['papers'])} papers on topic: {data['topic']}\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\" Error loading search results: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "oeSDjtjg_QX6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù 2. Filter Papers Having PDF Links"
      ],
      "metadata": {
        "id": "VOUhETsG_WRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_papers_with_pdfs(papers):\n",
        "    \"\"\"\n",
        "    Selects only papers that have a valid PDF URL.\n",
        "    \"\"\"\n",
        "    papers_with_pdf = [\n",
        "        p for p in papers\n",
        "        if p.get(\"pdf_url\") and (\"pdf\" in p[\"pdf_url\"].lower())\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n PDF Check:\")\n",
        "    print(f\" ‚Ä¢ Total papers: {len(papers)}\")\n",
        "    print(f\" ‚Ä¢ Papers with PDF URLs: {len(papers_with_pdf)}\")\n",
        "\n",
        "    return papers_with_pdf\n"
      ],
      "metadata": {
        "id": "E5V1W_4c_UMA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚≠ê 3. Rank Papers (Citations + Year)"
      ],
      "metadata": {
        "id": "CjNI57DG_jV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_papers(papers):\n",
        "    \"\"\"\n",
        "    Sorts papers by highest citation count and recent year.\n",
        "    \"\"\"\n",
        "    valid = [\n",
        "        p for p in papers\n",
        "        if p.get(\"citationCount\") is not None and p.get(\"year\")\n",
        "    ]\n",
        "\n",
        "    ranked = sorted(valid, key=lambda x: (x[\"citationCount\"], x[\"year\"]), reverse=True)\n",
        "    return ranked\n"
      ],
      "metadata": {
        "id": "ZimztT2i_bwC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ 4. Select Top N Papers"
      ],
      "metadata": {
        "id": "OQ9QeUGv_n1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_top_papers(papers, count=3):\n",
        "    \"\"\"\n",
        "    Selects the top N papers after:\n",
        "    1. PDF filtering\n",
        "    2. Ranking\n",
        "    \"\"\"\n",
        "    papers_with_pdf = filter_papers_with_pdfs(papers)\n",
        "    ranked = rank_papers(papers_with_pdf)\n",
        "    selected = ranked[:count]\n",
        "\n",
        "    print(f\"\\n Top {count} Selected Papers:\")\n",
        "    for i, p in enumerate(selected):\n",
        "        print(f\"\\n{i+1}. {p['title']}\")\n",
        "        print(f\"   ‚Ü≥ Citations: {p['citationCount']}, Year: {p['year']}\")\n",
        "\n",
        "    return selected\n"
      ],
      "metadata": {
        "id": "EvtmVEBn_r6e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 5. PDF Verification"
      ],
      "metadata": {
        "id": "UBfLS5B1_xOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_pdf(filepath):\n",
        "    \"\"\"\n",
        "    Checks if the file is a valid PDF using PyMuPDF.\n",
        "    Size <1KB is marked invalid.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(filepath):\n",
        "            return False\n",
        "        if os.path.getsize(filepath) < 1024:\n",
        "            return False\n",
        "        with fitz.open(filepath) as doc:\n",
        "            return len(doc) > 0\n",
        "    except:\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "2n0JXf9q_0mV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚¨á 6. Download PDF with Retry + Verification"
      ],
      "metadata": {
        "id": "DbDFKvpF_5TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_pdf_with_verification(url, filename, max_retries=3):\n",
        "    \"\"\"\n",
        "    Downloads a PDF from a URL.\n",
        "    Includes:\n",
        "    - Retry logic\n",
        "    - User-Agent header\n",
        "    - PDF file validation\n",
        "    \"\"\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0',\n",
        "        'Accept': 'application/pdf'\n",
        "    }\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            print(f\"  Attempt {attempt + 1}/{max_retries}...\")\n",
        "            response = requests.get(url, headers=headers, timeout=30, stream=True)\n",
        "\n",
        "            # Blocked access\n",
        "            if response.status_code == 403:\n",
        "                print(\"    HTTP 403 Forbidden. Retrying...\")\n",
        "                continue\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                print(f\"    HTTP Error: {response.status_code}\")\n",
        "                continue\n",
        "\n",
        "            # Save PDF\n",
        "            with open(filename, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "\n",
        "            # Validate\n",
        "            if verify_pdf(filename):\n",
        "                print(f\"    ‚úÖ Downloaded: {os.path.getsize(filename):,} bytes\")\n",
        "                return True\n",
        "            else:\n",
        "                print(\"    ‚ùå Invalid PDF. Retrying...\")\n",
        "                os.remove(filename)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {str(e)[:50]}\")\n",
        "\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "08DCXZ-g_3Cj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üì© 7. Download All Selected Papers"
      ],
      "metadata": {
        "id": "MFThcpekAUj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_selected_papers(selected, output_dir=\"downloads\"):\n",
        "    \"\"\"\n",
        "    Downloads the top N research paper PDFs into a folder.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    downloaded = []\n",
        "\n",
        "    for i, paper in enumerate(selected):\n",
        "        print(f\"\\n[{i+1}/{len(selected)}] Downloading:\")\n",
        "        print(\" \", paper['title'])\n",
        "\n",
        "        # Safe filename handling\n",
        "        safe_title = \"\".join(c for c in paper['title'] if c.isalnum())[:30]\n",
        "        filename = f\"{output_dir}/{safe_title}.pdf\"\n",
        "\n",
        "        if download_pdf_with_verification(paper[\"pdf_url\"], filename):\n",
        "            print(\"   ‚úÖ Success:\", filename)\n",
        "            paper[\"local_file\"] = filename\n",
        "            downloaded.append(paper)\n",
        "        else:\n",
        "            print(\"   ‚ùå Failed\")\n",
        "\n",
        "    return downloaded\n"
      ],
      "metadata": {
        "id": "b6ZOb6aoARC4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìÑ 8. Save JSON Download Report"
      ],
      "metadata": {
        "id": "Agmnmrm_Af89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_download_report(downloaded, topic):\n",
        "    \"\"\"\n",
        "    Creates a summary report of downloaded papers.\n",
        "    \"\"\"\n",
        "    os.makedirs(\"data/reports\", exist_ok=True)\n",
        "\n",
        "    report = {\n",
        "        \"topic\": topic,\n",
        "        \"download_count\": len(downloaded),\n",
        "        \"papers\": downloaded\n",
        "    }\n",
        "\n",
        "    output_file = f\"data/reports/download_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(report, f, indent=4)\n",
        "\n",
        "    print(\"\\n Report saved to:\", output_file)\n",
        "    return output_file\n"
      ],
      "metadata": {
        "id": "aiq6ve4wAeJI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ 9. Final Master Function (Module-2)"
      ],
      "metadata": {
        "id": "DKNp74nzAtnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# AUTO-LOAD LATEST SEARCH RESULTS\n",
        "# =======================================================\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def get_latest_search_results():\n",
        "    \"\"\"\n",
        "    Finds the most recent JSON file from data/search_results/\n",
        "    \"\"\"\n",
        "    folder_path = \"data/search_results/\"\n",
        "    json_files = glob.glob(os.path.join(folder_path, \"*.json\"))\n",
        "\n",
        "    if not json_files:\n",
        "        raise FileNotFoundError(\"‚ùå No search results found. Run Module 1 first.\")\n",
        "\n",
        "    latest_file = max(json_files, key=os.path.getctime)\n",
        "    print(f\"üìÑ Latest search results auto-loaded:\\n{latest_file}\")\n",
        "    return latest_file\n"
      ],
      "metadata": {
        "id": "kI-iQFZyAloV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_module2(top_n=3):\n",
        "    \"\"\"\n",
        "    MODULE 2 DRIVER FUNCTION\n",
        "    ------------------------\n",
        "    Auto-loads latest search results, selects top papers,\n",
        "    downloads PDFs, and generates a report.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n========== MODULE 2 STARTED ==========\\n\")\n",
        "\n",
        "    # Step 1: Auto-load latest search_results file\n",
        "    try:\n",
        "        json_path = get_latest_search_results()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERROR: Failed to load latest search results.\\n{e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 2: Load JSON content\n",
        "    data = load_search_results(json_path)\n",
        "    if not data:\n",
        "        print(\"‚ùå ERROR: search_results JSON is empty or unreadable.\")\n",
        "        return None\n",
        "\n",
        "    # Step 3: Filter & rank papers\n",
        "    print(\"\\nüìä Selecting top papers...\\n\")\n",
        "    selected = select_top_papers(data[\"papers\"], count=top_n)\n",
        "\n",
        "    # Step 4: Download selected PDFs\n",
        "    print(\"\\nüì• Downloading PDFs...\\n\")\n",
        "    downloaded = download_selected_papers(selected)\n",
        "\n",
        "    # Step 5: Save results\n",
        "    save_download_report(downloaded, data[\"topic\"])\n",
        "\n",
        "    print(\"\\n========== MODULE 2 COMPLETED ==========\\n\")\n",
        "\n",
        "    return downloaded\n"
      ],
      "metadata": {
        "id": "w5H_E3vXA1f5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_module2(top_n=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diLtZ-lhCpi8",
        "outputId": "8bacd091-1603-475b-cf7d-b37ba3b69eb8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== MODULE 2 STARTED ==========\n",
            "\n",
            "üìÑ Latest search results auto-loaded:\n",
            "data/search_results/search_results_20251211_195444.json\n",
            " Loaded 16 papers on topic: AI system to automatically review and summarize research papers\n",
            "\n",
            "üìä Selecting top papers...\n",
            "\n",
            "\n",
            " PDF Check:\n",
            " ‚Ä¢ Total papers: 16\n",
            " ‚Ä¢ Papers with PDF URLs: 4\n",
            "\n",
            " Top 3 Selected Papers:\n",
            "\n",
            "1. Automatic assessment of text-based responses in post-secondary education: A systematic review\n",
            "   ‚Ü≥ Citations: 91, Year: 2023\n",
            "\n",
            "2. Editorial for Special Issue on Large-scale Pre-training: Data, Models, and Fine-tuning\n",
            "   ‚Ü≥ Citations: 2, Year: 2023\n",
            "\n",
            "3. Special issue on future hybrid artificial intelligence and machine learning for smart expert systems\n",
            "   ‚Ü≥ Citations: 0, Year: 2021\n",
            "\n",
            "üì• Downloading PDFs...\n",
            "\n",
            "\n",
            "[1/3] Downloading:\n",
            "  Automatic assessment of text-based responses in post-secondary education: A systematic review\n",
            "  Attempt 1/3...\n",
            "    ‚úÖ Downloaded: 962,703 bytes\n",
            "   ‚úÖ Success: downloads/Automaticassessmentoftextbased.pdf\n",
            "\n",
            "[2/3] Downloading:\n",
            "  Editorial for Special Issue on Large-scale Pre-training: Data, Models, and Fine-tuning\n",
            "  Attempt 1/3...\n",
            "    ‚úÖ Downloaded: 380,064 bytes\n",
            "   ‚úÖ Success: downloads/EditorialforSpecialIssueonLarg.pdf\n",
            "\n",
            "[3/3] Downloading:\n",
            "  Special issue on future hybrid artificial intelligence and machine learning for smart expert systems\n",
            "  Attempt 1/3...\n",
            "    HTTP 403 Forbidden. Retrying...\n",
            "  Attempt 2/3...\n",
            "    HTTP 403 Forbidden. Retrying...\n",
            "  Attempt 3/3...\n",
            "    HTTP 403 Forbidden. Retrying...\n",
            "   ‚ùå Failed\n",
            "\n",
            " Report saved to: data/reports/download_report_20251211_201200.json\n",
            "\n",
            "========== MODULE 2 COMPLETED ==========\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'Automatic assessment of text-based responses in post-secondary education: A systematic review',\n",
              "  'authors': ['Rujun Gao',\n",
              "   'H. Merzdorf',\n",
              "   'S. Anwar',\n",
              "   'M. C. Hipwell',\n",
              "   'Arun Srinivasa'],\n",
              "  'year': 2023,\n",
              "  'pdf_url': 'https://arxiv.org/pdf/2308.16151',\n",
              "  'citationCount': 91,\n",
              "  'abstract': 'Text-based open-ended questions in academic formative and summative assessments help students become deep learners and prepare them to understand concepts for a subsequent conceptual assessment. However, grading text-based questions, especially in large courses, is tedious and time-consuming for instructors. Text processing models continue progressing with the rapid development of Artificial Intelligence (AI) tools and Natural Language Processing (NLP) algorithms. Especially after breakthroughs in Large Language Models (LLM), there is immense potential to automate rapid assessment and feedback of text-based responses in education. This systematic review adopts a scientific and reproducible literature search strategy based on the PRISMA process using explicit inclusion and exclusion criteria to study text-based automatic assessment systems in post-secondary education, screening 838 papers and synthesizing 93 studies. To understand how text-based automatic assessment systems have been developed and applied in education in recent years, three research questions are considered. All included studies are summarized and categorized according to a proposed comprehensive framework, including the input and output of the system, research motivation, and research outcomes, aiming to answer the research questions accordingly. Additionally, the typical studies of automated assessment systems, research methods, and application domains in these studies are investigated and summarized. This systematic review provides an overview of recent educational applications of text-based assessment systems for understanding the latest AI/NLP developments assisting in text-based assessments in higher education. Findings will particularly benefit researchers and educators incorporating LLMs such as ChatGPT into their educational activities.',\n",
              "  'url': 'https://www.semanticscholar.org/paper/2ced926ba4625fc08ac6685de16df2f142b3126f',\n",
              "  'local_file': 'downloads/Automaticassessmentoftextbased.pdf'},\n",
              " {'title': 'Editorial for Special Issue on Large-scale Pre-training: Data, Models, and Fine-tuning',\n",
              "  'authors': ['Jiying Wen', 'Zi-Hao Huang', 'Hanwang Zhang'],\n",
              "  'year': 2023,\n",
              "  'pdf_url': 'https://link.springer.com/content/pdf/10.1007/s11633-023-1431-y.pdf',\n",
              "  'citationCount': 2,\n",
              "  'abstract': None,\n",
              "  'url': 'https://www.semanticscholar.org/paper/72be13006e30a1601c0dfb0d3a2479006d1239c7',\n",
              "  'local_file': 'downloads/EditorialforSpecialIssueonLarg.pdf'}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}