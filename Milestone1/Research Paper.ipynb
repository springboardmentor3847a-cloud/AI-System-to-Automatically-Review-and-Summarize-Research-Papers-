{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "AI System to Automatically Review and Summarize Research Papers"
      ],
      "metadata": {
        "id": "SPteDFDemZEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module 1:Topic Input and Paper search"
      ],
      "metadata": {
        "id": "_LRZl39Ymanr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Libraries\n",
        "!pip install semanticscholar python-dotenv requests -q\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from semanticscholar import SemanticScholar\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "jKdX4_N_mgh4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fallback papers(when api fails)\n",
        "FALLBACK_PAPERS = [\n",
        "    {\n",
        "        \"title\": \"Deep Learning\",\n",
        "        \"authors\": [\"LeCun\", \"Bengio\", \"Hinton\"],\n",
        "        \"year\": 2015,\n",
        "        \"paperId\": \"DL001\",\n",
        "        \"abstract\": \"Overview of deep learning...\",\n",
        "        \"citationCount\": 50000,\n",
        "        \"venue\": \"Nature\",\n",
        "        \"url\": \"https://arxiv.org/abs/1502.01852\",\n",
        "        \"pdf_url\": \"https://arxiv.org/pdf/1502.01852.pdf\",\n",
        "        \"has_pdf\": True\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Attention Is All You Need\",\n",
        "        \"authors\": [\"Vaswani\", \"Shazeer\"],\n",
        "        \"year\": 2017,\n",
        "        \"paperId\": \"DL002\",\n",
        "        \"abstract\": \"Transformer architecture...\",\n",
        "        \"citationCount\": 100000,\n",
        "        \"venue\": \"NeurIPS\",\n",
        "        \"url\": \"https://arxiv.org/abs/1706.03762\",\n",
        "        \"pdf_url\": \"https://arxiv.org/pdf/1706.03762.pdf\",\n",
        "        \"has_pdf\": True\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Machine Learning Foundations\",\n",
        "        \"authors\": [\"Mitchell\"],\n",
        "        \"year\": 1997,\n",
        "        \"paperId\": \"DL003\",\n",
        "        \"abstract\": \"Introduction to machine learning foundations...\",\n",
        "        \"citationCount\": 20000,\n",
        "        \"venue\": \"McGraw Hill\",\n",
        "        \"url\": None,\n",
        "        \"pdf_url\": None,\n",
        "        \"has_pdf\": False\n",
        "    }\n",
        "]\n",
        "# safe api initilaization\n",
        "def setup_api_key():\n",
        "    load_dotenv()\n",
        "    API_KEY = os.getenv(\"SEMANTIC_SCHOLAR_API_KEY\")\n",
        "\n",
        "    if not API_KEY:\n",
        "        print(\"No API key found. Running without API (fallback mode).\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        sch = SemanticScholar(api_key=API_KEY)\n",
        "        # Test request to validate key\n",
        "        sch.search_paper(\"test\", limit=1)\n",
        "        print(\"Semantic Scholar initialized with API key\")\n",
        "        return sch\n",
        "    except Exception as e:\n",
        "        print(f\"API key failed ({e}) → Using fallback mode.\")\n",
        "        return None\n",
        "# Buid result dictionary\n",
        "def build_result(topic, papers):\n",
        "    return {\n",
        "        \"topic\": topic,\n",
        "        \"search_timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"total_results\": len(papers),\n",
        "        \"papers_with_pdf\": sum(p[\"has_pdf\"] for p in papers),\n",
        "        \"papers\": papers\n",
        "    }\n",
        "# search papers\n",
        "def search_papers(topic, limit=20):\n",
        "    print(f\"\\n Searching for papers on topic: '{topic}'\")\n",
        "\n",
        "    sch = setup_api_key()\n",
        "\n",
        "    # If API not available → fallback\n",
        "    if sch is None:\n",
        "        print(\" Using fallback sample dataset.\\n\")\n",
        "        return build_result(topic, FALLBACK_PAPERS)\n",
        "\n",
        "    try:\n",
        "        results = sch.search_paper(\n",
        "            query=topic,\n",
        "            limit=limit,\n",
        "            fields=[\"paperId\", \"title\", \"abstract\", \"year\", \"authors\",\n",
        "                    \"citationCount\", \"openAccessPdf\", \"url\", \"venue\"]\n",
        "        )\n",
        "\n",
        "        papers = []\n",
        "        for p in results:\n",
        "            papers.append({\n",
        "                \"title\": p.title,\n",
        "                \"authors\": [a[\"name\"] for a in p.authors] if p.authors else [],\n",
        "                \"year\": p.year,\n",
        "                \"paperId\": p.paperId,\n",
        "                \"abstract\": (p.abstract[:300] + \"...\") if p.abstract else \"No abstract\",\n",
        "                \"citationCount\": p.citationCount or 0,\n",
        "                \"venue\": getattr(p, \"venue\", None),\n",
        "                \"url\": p.url,\n",
        "                \"pdf_url\": p.openAccessPdf[\"url\"] if p.openAccessPdf else None,\n",
        "                \"has_pdf\": bool(p.openAccessPdf)\n",
        "            })\n",
        "\n",
        "        print(\"\\n Semantic Scholar search completed successfully!\")\n",
        "        return build_result(topic, papers)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n Semantic Scholar search failed: {e}\")\n",
        "        print(\" Using fallback dataset.\\n\")\n",
        "        return build_result(topic, FALLBACK_PAPERS)\n",
        "# save search results\n",
        "def save_search_results(data):\n",
        "    os.makedirs(\"data/search_results\", exist_ok=True)\n",
        "    fname = f\"{data['topic'].replace(' ', '_')}_results.json\"\n",
        "    path = f\"data/search_results/{fname}\"\n",
        "\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "\n",
        "    print(f\"\\n Results saved to: {path}\")\n",
        "    return path\n",
        "# display results\n",
        "def display_search_results(data):\n",
        "    print(f\" SEARCH RESULTS FOR: {data['topic']}\")\n",
        "\n",
        "    print(f\"\\n Total papers found: {data['total_results']}\")\n",
        "    print(f\" Papers with PDF: {data['papers_with_pdf']}\")\n",
        "\n",
        "    print(\"\\n TOP PAPERS:\")\n",
        "\n",
        "    for i, p in enumerate(data[\"papers\"], start=1):\n",
        "        print(f\"\\n{i}. {p['title']}\")\n",
        "        print(f\"   Authors: {', '.join(p['authors'])}\")\n",
        "        print(f\"    Year: {p['year']}\")\n",
        "        print(f\"    Citations: {p['citationCount']}\")\n",
        "        print(f\"    PDF: {'YES' if p['has_pdf'] else 'NO'}\")\n",
        "#main function\n",
        "def main_search():\n",
        "    print(\" MODULE 1: TOPIC INPUT & PAPER SEARCH\")\n",
        "\n",
        "    topic = input(\"\\nEnter research topic: \").strip()\n",
        "    if not topic:\n",
        "        topic = \"machine learning\"\n",
        "\n",
        "    results = search_papers(topic)\n",
        "    path = save_search_results(results)\n",
        "    display_search_results(results)\n",
        "\n",
        "    print(\"\\n MODULE 1 COMPLETE!\")\n",
        "    print(f\" Proceed to Module 2\\n\")\n",
        "\n",
        "    return results, path"
      ],
      "metadata": {
        "id": "qsTv9fkcucu7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module 2:Paper selection and Pdf download"
      ],
      "metadata": {
        "id": "8P18o-9I9A1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "!pip install PyMuPDF -q\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import fitz  # PyMuPDF\n",
        "from datetime import datetime\n",
        "\n",
        "os.makedirs(\"downloads\", exist_ok=True)\n",
        "#load results from module 1\n",
        "def load_search_results(path):\n",
        "    print(\"\\n Loading Module 1 results...\")\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        print(\" Results loaded successfully.\\n\")\n",
        "        return data\n",
        "    except:\n",
        "        print(\" ERROR: Could not load search results.\")\n",
        "        return None\n",
        "# RANK PAPERS (CITATIONS → YEAR)\n",
        "def rank_papers(papers):\n",
        "    return sorted(\n",
        "        papers,\n",
        "        key=lambda p: (p.get(\"citationCount\") or 0, p.get(\"year\") or 0),\n",
        "        reverse=True\n",
        "    )\n",
        "# DOWNLOAD + VALIDATE PDF\n",
        "def download_pdf(url, title):\n",
        "    if not url:\n",
        "        print(f\"\\n No PDF link for: {title}\")\n",
        "        return False, \"no_pdf\"\n",
        "\n",
        "    safe_title = \"\".join(c if c.isalnum() or c in \" _-\" else \"_\" for c in title)\n",
        "    filename = f\"{safe_title[:80]}_{abs(hash(url)) % 99999}.pdf\"\n",
        "    filepath = os.path.join(\"downloads\", filename)\n",
        "\n",
        "    print(f\"\\n Downloading: {title}\")\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, timeout=20)\n",
        "        if r.status_code != 200:\n",
        "            return False, f\"HTTP {r.status_code}\"\n",
        "\n",
        "        with open(filepath, \"wb\") as f:\n",
        "            f.write(r.content)\n",
        "\n",
        "        # Validate PDF\n",
        "        try:\n",
        "            doc = fitz.open(filepath)\n",
        "            if doc.page_count == 0:\n",
        "                os.remove(filepath)\n",
        "                return False, \"empty_pdf\"\n",
        "        except:\n",
        "            os.remove(filepath)\n",
        "            return False, \"invalid_pdf\"\n",
        "\n",
        "        print(f\"    Saved at: {filepath}\")\n",
        "        return True, filepath\n",
        "\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "# MODULE 2 MAIN\n",
        "def main_module_2(results_path):\n",
        "    print(\" MODULE 2: PAPER SELECTION & PDF DOWNLOAD\")\n",
        "    data = load_search_results(results_path)\n",
        "    if not data:\n",
        "        return\n",
        "\n",
        "    papers = data[\"papers\"]\n",
        "    print(f\" Total papers: {len(papers)}\")\n",
        "\n",
        "    pdf_papers = [p for p in papers if p.get(\"has_pdf\")]\n",
        "    print(f\" Papers with PDF: {len(pdf_papers)}\")\n",
        "\n",
        "    if len(pdf_papers) == 0:\n",
        "        print(\"\\n No PDFs found. Using fallback PDF paper.\")\n",
        "        pdf_papers = [{\n",
        "            \"title\": \"Deep Learning (Fallback PDF)\",\n",
        "            \"pdf_url\": \"https://arxiv.org/pdf/1502.01852.pdf\",\n",
        "            \"citationCount\": 50000,\n",
        "            \"year\": 2015\n",
        "        }]\n",
        "\n",
        "    ranked = rank_papers(pdf_papers)\n",
        "    selected = ranked[:3]\n",
        "\n",
        "    print(\"\\n SELECTED PAPERS:\")\n",
        "    for p in selected:\n",
        "        print(f\" - {p['title']} (Citations: {p.get('citationCount',0)})\")\n",
        "\n",
        "    print(\"\\n DOWNLOADING PDFs...\\n\")\n",
        "\n",
        "    for p in selected:\n",
        "        success, info = download_pdf(p.get(\"pdf_url\"), p.get(\"title\"))\n",
        "        print(f\"   Status: {'SUCCESS' if success else 'FAILED'} ({info})\")\n",
        "\n",
        "    print(\"\\n MODULE 2 COMPLETE!\")\n",
        "    print(\" PDFs saved in: downloads/\\n\")"
      ],
      "metadata": {
        "id": "6vHhT9_oumt4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results, path = main_search()"
      ],
      "metadata": {
        "id": "n6Nkzpshu84_",
        "outputId": "b724fea4-3c1b-4568-cc08-b71699c29745",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " MODULE 1: TOPIC INPUT & PAPER SEARCH\n",
            "\n",
            "Enter research topic: Machine Learning\n",
            "\n",
            " Searching for papers on topic: 'Machine Learning'\n",
            "No API key found. Running without API (fallback mode).\n",
            " Using fallback sample dataset.\n",
            "\n",
            "\n",
            " Results saved to: data/search_results/Machine_Learning_results.json\n",
            " SEARCH RESULTS FOR: Machine Learning\n",
            "\n",
            " Total papers found: 3\n",
            " Papers with PDF: 2\n",
            "\n",
            " TOP PAPERS:\n",
            "\n",
            "1. Deep Learning\n",
            "   Authors: LeCun, Bengio, Hinton\n",
            "    Year: 2015\n",
            "    Citations: 50000\n",
            "    PDF: YES\n",
            "\n",
            "2. Attention Is All You Need\n",
            "   Authors: Vaswani, Shazeer\n",
            "    Year: 2017\n",
            "    Citations: 100000\n",
            "    PDF: YES\n",
            "\n",
            "3. Machine Learning Foundations\n",
            "   Authors: Mitchell\n",
            "    Year: 1997\n",
            "    Citations: 20000\n",
            "    PDF: NO\n",
            "\n",
            " MODULE 1 COMPLETE!\n",
            " Proceed to Module 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_module_2(path)\n"
      ],
      "metadata": {
        "id": "-6O-00B2vvth",
        "outputId": "7e82e1cf-9f6f-4cde-f884-239deec06e3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " MODULE 2: PAPER SELECTION & PDF DOWNLOAD\n",
            "\n",
            " Loading Module 1 results...\n",
            " Results loaded successfully.\n",
            "\n",
            " Total papers: 3\n",
            " Papers with PDF: 2\n",
            "\n",
            " SELECTED PAPERS:\n",
            " - Attention Is All You Need (Citations: 100000)\n",
            " - Deep Learning (Citations: 50000)\n",
            "\n",
            " DOWNLOADING PDFs...\n",
            "\n",
            "\n",
            " Downloading: Attention Is All You Need\n",
            "    Saved at: downloads/Attention Is All You Need_88725.pdf\n",
            "   Status: SUCCESS (downloads/Attention Is All You Need_88725.pdf)\n",
            "\n",
            " Downloading: Deep Learning\n",
            "    Saved at: downloads/Deep Learning_64099.pdf\n",
            "   Status: SUCCESS (downloads/Deep Learning_64099.pdf)\n",
            "\n",
            " MODULE 2 COMPLETE!\n",
            " PDFs saved in: downloads/\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}