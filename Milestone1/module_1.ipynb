{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927f9d0a",
   "metadata": {},
   "source": [
    "# Module 1 : Topic Input & Paper Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bfa5d",
   "metadata": {},
   "source": [
    "### Install and Import required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999f3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install semanticscholar python-dotenv requests -q\n",
    "\n",
    "import json\n",
    "import os\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from semanticscholar import SemanticScholar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad56ec",
   "metadata": {},
   "source": [
    "### Setup API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc5594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_api_key() -> SemanticScholar:\n",
    "    \"\"\"\n",
    "    Initialize and return a SemanticScholar client.\n",
    "\n",
    "    Behavior:\n",
    "    - Attempts to load SEMANTIC_SCHOLAR_API_KEY from a .env file.\n",
    "    - If not found, does NOT write a real API key to disk (hard-coded keys removed).\n",
    "      Instead, continues without a key (limited rate) and prints clear instructions.\n",
    "    - Returns an initialized SemanticScholar client (with or without api_key).\n",
    "\n",
    "    Returns:\n",
    "        SemanticScholar: Initialized client object.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv(\"SEMANTIC_SCHOLAR_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\n",
    "            \"SEMANTIC_SCHOLAR_API_KEY not found in environment. \"\n",
    "            \"Proceeding without API key (limited rate).\"\n",
    "        )\n",
    "        print(\n",
    "            \"To use a key: create a .env file with a line like:\\n\"\n",
    "            \"SEMANTIC_SCHOLAR_API_KEY=83rBkeaXb14D8vGpXJezU6nrCFFmyn5L8RCvT9MM\\n\"\n",
    "            \"Then re-run this script.\"\n",
    "        )\n",
    "        scholar_client = SemanticScholar()\n",
    "    else:\n",
    "        scholar_client = SemanticScholar(api_key=api_key)\n",
    "        print(\"Semantic Scholar initialized with API key.\")\n",
    "\n",
    "    return scholar_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b942c64",
   "metadata": {},
   "source": [
    "### Search Research Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1b881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, limit: int = 20) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Search Semantic Scholar for papers on a given topic.\n",
    "\n",
    "    Args:\n",
    "        topic (str): Topic/query string for searching papers.\n",
    "        limit (int): Maximum number of papers to request.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: Dictionary containing search metadata and papers list\n",
    "                      or None if an error occurred.\n",
    "    \"\"\"\n",
    "    if not topic or not topic.strip():\n",
    "        raise ValueError(\"search_papers requires a non-empty topic string.\")\n",
    "\n",
    "    print(f\"\\nSearching for papers on: '{topic}' (limit={limit})\")\n",
    "\n",
    "    scholar_client = setup_api_key()\n",
    "\n",
    "    try:\n",
    "        # Request fields that are useful downstream\n",
    "        results = scholar_client.search_paper(\n",
    "            query=topic,\n",
    "            limit=limit,\n",
    "            fields=[\n",
    "                \"paperId\", \"title\", \"abstract\", \"year\", \"authors\",\n",
    "                \"citationCount\", \"openAccessPdf\", \"url\", \"venue\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        papers: List[Dict[str, Any]] = []\n",
    "\n",
    "        for paper in results:\n",
    "            raw_authors = getattr(paper, \"authors\", []) or []\n",
    "            authors: List[str] = []\n",
    "            for a in raw_authors:\n",
    "                if hasattr(a, \"name\"):\n",
    "                    authors.append(getattr(a, \"name\"))\n",
    "                elif isinstance(a, dict) and \"name\" in a:\n",
    "                    authors.append(a[\"name\"])\n",
    "                else:\n",
    "                    authors.append(str(a))\n",
    "\n",
    "            open_access_pdf = getattr(paper, \"openAccessPdf\", None)\n",
    "            pdf_url = None\n",
    "            has_pdf = False\n",
    "            if open_access_pdf:\n",
    "                if isinstance(open_access_pdf, dict):\n",
    "                    pdf_url = open_access_pdf.get(\"url\")\n",
    "                else:\n",
    "                    pdf_url = getattr(open_access_pdf, \"get\", lambda x: None)(\"url\")\n",
    "                has_pdf = bool(pdf_url)\n",
    "\n",
    "            paper_entry = {\n",
    "                \"title\": getattr(paper, \"title\", \"\") or \"No title\",\n",
    "                \"authors\": authors,\n",
    "                \"year\": getattr(paper, \"year\", None),\n",
    "                \"paperId\": getattr(paper, \"paperId\", None),\n",
    "                \"abstract\": (getattr(paper, \"abstract\", \"\") or \"\")[:300] + (\"...\" if getattr(paper, \"abstract\", None) and len(getattr(paper, \"abstract\", \"\")) > 300 else \"\"),\n",
    "                \"citationCount\": getattr(paper, \"citationCount\", 0),\n",
    "                \"venue\": getattr(paper, \"venue\", None),\n",
    "                \"url\": getattr(paper, \"url\", None),\n",
    "                \"pdf_url\": pdf_url,\n",
    "                \"has_pdf\": has_pdf\n",
    "            }\n",
    "            papers.append(paper_entry)\n",
    "\n",
    "        papers_with_pdf = sum(1 for p in papers if p[\"has_pdf\"])\n",
    "\n",
    "        print(\"Search complete!\")\n",
    "        print(f\"  Total papers returned: {len(papers)}\")\n",
    "        print(f\"  Papers with PDF available: {papers_with_pdf}\")\n",
    "\n",
    "        return {\n",
    "            \"topic\": topic,\n",
    "            \"search_timestamp\": datetime.now().isoformat(),\n",
    "            \"total_results\": len(papers),\n",
    "            \"papers_with_pdf\": papers_with_pdf,\n",
    "            \"papers\": papers\n",
    "        }\n",
    "\n",
    "    except Exception as exc:\n",
    "        print(f\"Error searching papers: {exc}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4386be9",
   "metadata": {},
   "source": [
    "### Save Search Research Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968ce73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_search_results(data: Dict[str, Any], filename: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Save search results dict to a JSON file under data/search_results.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Data returned by `search_papers`.\n",
    "        filename (str, optional): Custom filename. If None, generate from topic.\n",
    "\n",
    "    Returns:\n",
    "        str: Full path of the saved JSON file.\n",
    "    \"\"\"\n",
    "    if not data or \"topic\" not in data:\n",
    "        raise ValueError(\"save_search_results requires data dictionary with a 'topic' key.\")\n",
    "\n",
    "    # Create a filesystem-safe filename if not provided\n",
    "    if not filename:\n",
    "        safe_topic = \"\".join(c for c in data[\"topic\"] if c.isalnum() or c == \" \").strip()\n",
    "        safe_topic = safe_topic.replace(\" \", \"_\") or \"search\"\n",
    "        filename = f\"paper_search_results_{safe_topic}.json\"\n",
    "\n",
    "    os.makedirs(\"data/search_results\", exist_ok=True)\n",
    "    filepath = os.path.join(\"data/search_results\", filename)\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as fh:\n",
    "        json.dump(data, fh, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Search results saved to: {filepath}\")\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f72801b",
   "metadata": {},
   "source": [
    "### Display the Searched Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f476d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_search_results(data: Dict[str, Any], max_display: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Display search results as a pandas DataFrame (table).\n",
    "\n",
    "    If running in a Jupyter / notebook environment the DataFrame will render\n",
    "    as a nice HTML table. In a plain console, the DataFrame will be printed\n",
    "    as text. Shows top `max_display` papers.\n",
    "    \"\"\"\n",
    "    if not data or \"papers\" not in data:\n",
    "        print(\"No data to display.\")\n",
    "        return\n",
    "\n",
    "    papers = data[\"papers\"]\n",
    "    total = len(papers)\n",
    "    pdf_count = sum(1 for p in papers if p.get(\"has_pdf\"))\n",
    "    no_pdf_count = total - pdf_count\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 72)\n",
    "    print(f\"SEARCH RESULTS: {data.get('topic', 'Unknown topic')}\")\n",
    "    print(\"=\" * 72)\n",
    "    print(\"\\nStatistics:\")\n",
    "    print(f\"  • Total papers: {total}\")\n",
    "    print(f\"  • Papers with PDF: {pdf_count}\")\n",
    "    print(f\"  • Papers without PDF: {no_pdf_count}\")\n",
    "\n",
    "    to_show = min(max_display, total)\n",
    "    if to_show == 0:\n",
    "        print(\"\\nNo papers to display.\")\n",
    "        return\n",
    "\n",
    "    # Build rows for DataFrame\n",
    "    rows = []\n",
    "    for idx, paper in enumerate(papers[:to_show], start=1):\n",
    "        title = paper.get(\"title\", \"\") or \"\"\n",
    "        authors = paper.get(\"authors\", []) or []\n",
    "        authors_display = \", \".join(authors)\n",
    "        year = paper.get(\"year\", \"\")\n",
    "        citations = paper.get(\"citationCount\", 0)\n",
    "        has_pdf = paper.get(\"has_pdf\", False)\n",
    "        pdf_url = paper.get(\"pdf_url\", \"\") or \"\"\n",
    "        url = paper.get(\"url\", \"\") or \"\"\n",
    "        abstract = (paper.get(\"abstract\") or \"\")\n",
    "        if len(abstract) > 300:\n",
    "            abstract = abstract[:297] + \"...\"\n",
    "\n",
    "        rows.append({\n",
    "            \"#\": idx,\n",
    "            \"Title\": title,\n",
    "            \"Authors\": authors_display,\n",
    "            \"Year\": year,\n",
    "            \"Citations\": citations,\n",
    "            \"Has PDF\": has_pdf,\n",
    "            \"PDF URL\": pdf_url,\n",
    "            \"URL\": url,\n",
    "            \"Abstract\": abstract\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    col_order = [\"#\", \"Title\", \"Authors\", \"Year\", \"Citations\", \"Has PDF\", \"PDF URL\", \"URL\", \"Abstract\"]\n",
    "    df = df[col_order]\n",
    "\n",
    "    try:\n",
    "        from IPython.display import display as _display, HTML\n",
    "        _display(df)\n",
    "    except Exception:\n",
    "        pd.set_option(\"display.max_colwidth\", 120)\n",
    "        print(\"\\nTop results (DataFrame):\\n\")\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "    print(f\"\\nShowing top {to_show} of {total} papers. Use `max_display` to change the table size.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10a6fe",
   "metadata": {},
   "source": [
    "### Main Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94c0a73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "MODULE 1: TOPIC INPUT & PAPER SEARCH\n",
      "========================================================================\n",
      "\n",
      "Enter research topic: data engineering\n",
      "\n",
      "Searching for papers on: 'data engineering' (limit=20)\n",
      "Semantic Scholar initialized with API key.\n",
      "Search complete!\n",
      "  Total papers returned: 1000\n",
      "  Papers with PDF available: 328\n",
      "Search results saved to: data/search_results\\paper_search_results_data_engineering.json\n",
      "\n",
      "========================================================================\n",
      "SEARCH RESULTS: data engineering\n",
      "========================================================================\n",
      "\n",
      "Statistics:\n",
      "  • Total papers: 1000\n",
      "  • Papers with PDF: 328\n",
      "  • Papers without PDF: 672\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Has PDF</th>\n",
       "      <th>PDF URL</th>\n",
       "      <th>URL</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Engineering for Scaling Language Models t...</td>\n",
       "      <td>Yao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue,...</td>\n",
       "      <td>2024</td>\n",
       "      <td>178</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>https://www.semanticscholar.org/paper/f288e223...</td>\n",
       "      <td>We study the continual pretraining recipe for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Detecting drifts in data streams using Kullbac...</td>\n",
       "      <td>Jeomoan Francis Kurian, Mohamed Allali</td>\n",
       "      <td>2024</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>https://link.springer.com/content/pdf/10.1007/...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/1a350c69...</td>\n",
       "      <td>The exponential growth of data coupled with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Evolution of Data Engineering in Modern Softwa...</td>\n",
       "      <td>Santhosh Bussa</td>\n",
       "      <td>2024</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>https://jss.thewriters.in/index.php/jss/articl...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/b41c6f42...</td>\n",
       "      <td>Data engineering is ever-evolving and is now i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What About the Data? A Mapping Study on Data E...</td>\n",
       "      <td>Petra Heck</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>https://dl.acm.org/doi/pdf/10.1145/3644815.364...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/5741458e...</td>\n",
       "      <td>AI systems cannot exist without data. Now that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A Survey of Pipeline Tools for Data Engineering</td>\n",
       "      <td>Anthony Mbata, Yaji Sripada, Mingjun Zhong</td>\n",
       "      <td>2024</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>https://www.semanticscholar.org/paper/5dc405e2...</td>\n",
       "      <td>Currently, a variety of pipeline tools are ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>LLMs for Data Engineering on Enterprise Data</td>\n",
       "      <td>Jan-Micha Bodensohn, Ulf Brackmann, Liane Voge...</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>https://www.semanticscholar.org/paper/2f6fb4fa...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Adapting Large Language Models for Content Mod...</td>\n",
       "      <td>Huan Ma, Changqing Zhang, Huazhu Fu, Peilin Zh...</td>\n",
       "      <td>2023</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>https://arxiv.org/pdf/2310.03400</td>\n",
       "      <td>https://www.semanticscholar.org/paper/fbc32b68...</td>\n",
       "      <td>Nowadays, billions of people engage in communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Enhancing Data Engineering Frameworks for Scal...</td>\n",
       "      <td>Balachandar Paulraj</td>\n",
       "      <td>2023</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>https://www.semanticscholar.org/paper/f6760ffd...</td>\n",
       "      <td>This report discusses improvements to the data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Integrating Data Engineering with Intelligent ...</td>\n",
       "      <td>Roja Boina, Alekhya Achanta, Shreekant Mandvikar</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>https://doi.org/10.21275/sr231123225415</td>\n",
       "      <td>https://www.semanticscholar.org/paper/27d0917a...</td>\n",
       "      <td>: This article investigates the integration of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Supercharging Distributed Computing Environmen...</td>\n",
       "      <td>Niranda Perera, Kaiying Shan, Supun Kamburugam...</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/pdf/2301.07896</td>\n",
       "      <td>https://www.semanticscholar.org/paper/bb2116ba...</td>\n",
       "      <td>The data engineering and data science communit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    #                                              Title  \\\n",
       "0   1  Data Engineering for Scaling Language Models t...   \n",
       "1   2  Detecting drifts in data streams using Kullbac...   \n",
       "2   3  Evolution of Data Engineering in Modern Softwa...   \n",
       "3   4  What About the Data? A Mapping Study on Data E...   \n",
       "4   5    A Survey of Pipeline Tools for Data Engineering   \n",
       "5   6       LLMs for Data Engineering on Enterprise Data   \n",
       "6   7  Adapting Large Language Models for Content Mod...   \n",
       "7   8  Enhancing Data Engineering Frameworks for Scal...   \n",
       "8   9  Integrating Data Engineering with Intelligent ...   \n",
       "9  10  Supercharging Distributed Computing Environmen...   \n",
       "\n",
       "                                             Authors  Year  Citations  \\\n",
       "0  Yao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue,...  2024        178   \n",
       "1             Jeomoan Francis Kurian, Mohamed Allali  2024         19   \n",
       "2                                     Santhosh Bussa  2024         13   \n",
       "3                                         Petra Heck  2024         10   \n",
       "4         Anthony Mbata, Yaji Sripada, Mingjun Zhong  2024          8   \n",
       "5  Jan-Micha Bodensohn, Ulf Brackmann, Liane Voge...  2024          5   \n",
       "6  Huan Ma, Changqing Zhang, Huazhu Fu, Peilin Zh...  2023         30   \n",
       "7                                Balachandar Paulraj  2023         29   \n",
       "8   Roja Boina, Alekhya Achanta, Shreekant Mandvikar  2023          9   \n",
       "9  Niranda Perera, Kaiying Shan, Supun Kamburugam...  2023          9   \n",
       "\n",
       "   Has PDF                                            PDF URL  \\\n",
       "0    False                                                      \n",
       "1     True  https://link.springer.com/content/pdf/10.1007/...   \n",
       "2     True  https://jss.thewriters.in/index.php/jss/articl...   \n",
       "3     True  https://dl.acm.org/doi/pdf/10.1145/3644815.364...   \n",
       "4    False                                                      \n",
       "5    False                                                      \n",
       "6     True                   https://arxiv.org/pdf/2310.03400   \n",
       "7    False                                                      \n",
       "8     True            https://doi.org/10.21275/sr231123225415   \n",
       "9     True                    http://arxiv.org/pdf/2301.07896   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.semanticscholar.org/paper/f288e223...   \n",
       "1  https://www.semanticscholar.org/paper/1a350c69...   \n",
       "2  https://www.semanticscholar.org/paper/b41c6f42...   \n",
       "3  https://www.semanticscholar.org/paper/5741458e...   \n",
       "4  https://www.semanticscholar.org/paper/5dc405e2...   \n",
       "5  https://www.semanticscholar.org/paper/2f6fb4fa...   \n",
       "6  https://www.semanticscholar.org/paper/fbc32b68...   \n",
       "7  https://www.semanticscholar.org/paper/f6760ffd...   \n",
       "8  https://www.semanticscholar.org/paper/27d0917a...   \n",
       "9  https://www.semanticscholar.org/paper/bb2116ba...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  We study the continual pretraining recipe for ...  \n",
       "1  The exponential growth of data coupled with th...  \n",
       "2  Data engineering is ever-evolving and is now i...  \n",
       "3  AI systems cannot exist without data. Now that...  \n",
       "4  Currently, a variety of pipeline tools are ava...  \n",
       "5                                                     \n",
       "6  Nowadays, billions of people engage in communi...  \n",
       "7  This report discusses improvements to the data...  \n",
       "8  : This article investigates the integration of...  \n",
       "9  The data engineering and data science communit...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing top 10 of 1000 papers. Use `max_display` to change the table size.\n",
      "\n",
      "Module 1 complete. Results saved to: data/search_results\\paper_search_results_data_engineering.json\n",
      "Proceed to Module 2 for paper selection and PDF download.\n"
     ]
    }
   ],
   "source": [
    "def main_search() -> (Optional[Dict[str, Any]], Optional[str]):\n",
    "    \"\"\"\n",
    "    Interactive main entry for Module 1.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (results dict or None, path to saved file or None).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 72)\n",
    "    print(\"MODULE 1: TOPIC INPUT & PAPER SEARCH\")\n",
    "    print(\"=\" * 72)\n",
    "\n",
    "    try:\n",
    "        topic = input(\"\\nEnter research topic: \").strip()\n",
    "    except Exception:\n",
    "        topic = \"\"\n",
    "\n",
    "    if not topic:\n",
    "        topic = \"artificial intelligence\"\n",
    "\n",
    "    results = search_papers(topic, limit=20)\n",
    "    if not results:\n",
    "        print(\"No results found or an error occurred during search.\")\n",
    "        return None, None\n",
    "\n",
    "    save_path = save_search_results(results)\n",
    "    display_search_results(results)\n",
    "\n",
    "    print(\"\\nModule 1 complete. Results saved to:\", save_path)\n",
    "    print(\"Proceed to Module 2 for paper selection and PDF download.\")\n",
    "    return results, save_path\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d555dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
