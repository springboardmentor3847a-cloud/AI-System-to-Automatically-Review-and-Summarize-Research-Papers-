{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folders = [\n",
        "    \"data/pdfs\",\n",
        "    \"data/extracted_text\",\n",
        "    \"data/structured_sections\",\n",
        "    \"data/comparisons\"\n",
        "]\n",
        "\n",
        "for folder in folders:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "print(\"Folders created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7K85yODO695",
        "outputId": "2d30ef5a-bbc1-41cd-f70a-6be6a8a049ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "import re\n",
        "import json\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "id": "BFxG2kI7PAYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    doc.close()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "A4dliPtTQnRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/data/pdfs/2512.00419v1.pdf\"\n",
        "text = extract_text_from_pdf(pdf_path)\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDbyrFn-QqAQ",
        "outputId": "fa6bba94-0c2d-48b0-a3ef-95f382404b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hardware-aware Lightweight Photonic Spiking Neural \n",
            "Network for Pattern Classification \n",
            "Shuiying Xiang1*, Yahui Zhang1, Shangxuan Shi1, Haowen Zhao1, Dianzhuang Zheng1, \n",
            "Xingxing Guo1, Yanan Han1, Ye Tian1, Liyue Zhang2, Yuechun Shi3, & Yue Hao1 \n",
            "1State Key Laboratory of Integrated Service Networks, State Key Discipline Laboratory of Wide Bandgap Semiconductor Technology, \n",
            "Xidian University, Xi'an 710071, China; \n",
            "2Key Laboratory of Photonic-Electronic Integration and Communication-Sensing Convergence (Ministry of Education), Southwest \n",
            "Jiaotong University, Sichuan, 611756, China; \n",
            "3Yongjiang laboratory, No. 1792 Cihai South Road, Ningbo 315202, China. \n",
            "*Corresponding author: syxiang@xidian.edu.cn \n",
            "Received 19 Nov. 2025; revised XX Month, XXXX; accepted XX Month XXXX; posted XX Month XXXX (Doc. ID XXXXX); published XX Month XXXX \n",
            "There exists a significant scale gap between photonic neural network integrated chips and neural networks, which hinders the deployment \n",
            "and application of photonic neural network. Here, we propose hardware-aware lightweight spiking neural networks (SNNs) architecture \n",
            "tailored to our photonic neuromorphic chips, and conducts hardware-software collaborative computing for solving patter classification tasks. \n",
            "Here, we employed a simplified Mach-Zehnder interferometer (MZI) mesh for performing linear computation, and 16-channel distributed \n",
            "feedback lasers with saturable absorber (DFB-SA) array for performing nonlinear spike activation. Both photonic neuromorphic chips based \n",
            "on the MZI mesh and DFB-SA array were designed, optimized and fabricated. Furthermore, we propose a lightweight spiking neural network \n",
            "(SNN) with discrete cosine transform to reduce input dimension and match the input/output ports number of the photonic neuromorphic \n",
            "chips. We demonstrated an end-to-end inference of an entire layer of the lightweight photonic SNN. The hardware-software collaborative \n",
            "inference accuracy is 90% and 80.5% for MNIST and Fashion-MNIST datasets, respectively. The energy efficiency is 1.39 TOPS/W for the MZI \n",
            "mesh, and is 987.65 GOPS/W for the DFB-SA array. The lightweight architecture and experimental demonstration address the challenge of \n",
            "scale mismatch between the photonic chip and SNN, paving the way for the hardware deployment of photonic SNNs. \n",
            " \n",
            "Keywords: Photonic neuromorphic; photonic spiking neural network; pattern classification \n",
            " \n",
            "1. INTRODUCTION \n",
            "With the rapid development of artificial intelligence (AI) \n",
            "represented by ChatGPT and Deepseek, the demand for computing \n",
            "power has shown explosive growth. Traditional electronic \n",
            "computing chips based on the von Neumann architecture are facing \n",
            "severe challenges of the \"memory wall\" and \"power wall\", and their \n",
            "computing power growth is gradually approaching physical limits. \n",
            "Photonic neural networks (PNNs) stand out with their ultra-high \n",
            "speed, ultra-low power consumption, and inherent large-scale \n",
            "parallel processing capabilities, becoming one of the most promising \n",
            "disruptive computing paradigms in the post-Moore era [1 - 12]. \n",
            "In recent years, PNNs based on Mach-Zehnder interferometers \n",
            "(MZI) [13 - 23], micro-ring resonator [24 - 27], phase change material \n",
            "crossbars [28 - 30], and spiking laser neurons [31 - 37] have been studied \n",
            "extensively. Specifically, programmable MZI mesh-based PNN \n",
            "chips have been developed rapidly since 2017, with their matrix \n",
            "scale gradually advancing from the initial 4√ó4 [13, 14] to the \n",
            "sophisticated 128√ó128 [22, 23]. For diverse photonic computing \n",
            "paradigms, reported PNNs implementations cover photonic multi-\n",
            "layer perceptrons [38 ‚Äì 39], convolutional neural networks [40 ‚Äì 43], tensor \n",
            "processing [44 - 48], and diffractive neural networks [49 ‚Äì 55]. \n",
            "Among numerous neural network models, spiking neural \n",
            "networks (SNNs) have attracted significant attention due to their \n",
            "adoption of the efficient and sparse processing mechanisms of the \n",
            "biological brain. Combining the ultra-high speed and low-power \n",
            "advantages of photonic technology with the biologically inspired \n",
            "efficiency of SNNs has spawned the emerging interdisciplinary field \n",
            "of photonic spiking neural networks (PSNNs). PSNNs are expected \n",
            "to achieve remarkable computing speeds while keeping energy \n",
            "consumption at an extremely low level, providing an ideal hardware \n",
            "solution for scenarios such as edge computing and real-time \n",
            "intelligent processing. In addition, these photonic SNN systems \n",
            "exhibit outstanding noise immunity while alleviating the stringent \n",
            "requirements for high-precision analog-to-digital (AD) and digital-\n",
            "to-analog (DA) conversions during the input of spike signals and \n",
            "retrieval of spike output data. Consequently, PSNN emerges as a \n",
            "hardware-friendly architecture. Recently, PSNNs have attracted \n",
            "numerous attention [28, 32-37, 56 - 60]. However, there is a huge gap \n",
            "between the scale of actual photonic neuromorphic chips and the \n",
            "scale of SNNs required to complete specific tasks. This mismatch in \n",
            "scale between \"software\" (neural network models) and \"hardware\" \n",
            "(neuromorphic chips) seriously hinders the transition of PSNNs \n",
            "from theoretical models to practical applications. \n",
            "To address this core contradiction, the key lies in model \n",
            "compression of PSNNs. That is, on the premise of maintaining their \n",
            "core functions and performance, the complexity and scale of the \n",
            "model are significantly reduced to enable efficient deployment on \n",
            "resource-constrained \n",
            "photonic \n",
            "chips. \n",
            "Traditional \n",
            "model \n",
            "compression methods, such as pruning and quantization, have been \n",
            "applied in electronic SNNs, but they often fail to fully consider the \n",
            "unique physical characteristics and hardware constraints of photonic \n",
            "computing. Therefore, there is an urgent need for a new lightweight \n",
            "architecture that is highly compatible with the characteristics of \n",
            "photonic hardware. \n",
            "We propose a lightweight PSNN architecture based on discrete \n",
            "cosine transform (DCT) [61], and deploys this network on a photonic \n",
            "neuromorphic chip for hardware-software collaborative computing, \n",
            "aiming to fundamentally bridge the gap between algorithm scale and \n",
            "hardware chip size. We introduce DCT into the design of PSNNs to \n",
            "reduce the dimensionality and remove redundancy of input data, \n",
            "retaining only the most informative frequency components as inputs \n",
            "to the SNN. This fundamentally reduces the dimensionality of \n",
            "processed data and the scale required for subsequent networks, \n",
            "thereby making it possible to deploy the entire SNN on a photonic \n",
            "chip. We consider a fully connected network architecture in order to \n",
            "achieve single-time-step SNN training and completed classification \n",
            "tasks on MNIST and Fashion-MNIST datasets. The hardware-\n",
            "software inference based on the photonic neuromorphic chip and the \n",
            "lightweight PSNN are further carried out. The work not only \n",
            "provides an innovative technical solution to address the scale \n",
            "bottleneck of PSNNs, but also takes a key step in promoting the \n",
            "transition of photonic neuromorphic computing from the laboratory \n",
            "to practical applications such as edge computation and embodied \n",
            "intelligence. \n",
            "2. Experimental setup and Method  \n",
            "A. Lightweight architecture of PSNN with DCT. \n",
            "To match the limited fan-in size of the photonic neuromorphic \n",
            "computing chip, we propose a frequency-domain pruning method \n",
            "by applying DCT to the input image of the SNN. As shown in \n",
            "Fig.1(a), after DCT, the frequency spectrum of the input image is \n",
            " \n",
            "Fig. 1. (a) The overall architecture of the frequency-domain SNN with DCT, (b) schematic diagram of photonic linear computation and \n",
            "photonic LIF neuron, (c) microscopic image of the fabricated MZI mesh chip, (d) microscopic image of the fabricated DFB-SA array chip \n",
            "(e) The testing experimental setup.  \n",
            "obtained. We select the low-frequency components and feed them \n",
            "into the SNN for further processing, which significantly reduces the \n",
            "input size of the SNN. The frequency-domain components are \n",
            "flattened and then fed into the first linear layer of the SNN. Following \n",
            "the linear layer, the weighted summation signals are conveyed to the \n",
            "leaky integrate-and-fire (LIF) neuron for nonlinear spike activation. \n",
            "Different hidden layers can be considered for different tasks.  \n",
            "The DCT is a mathematical transformation that converts spatial \n",
            "domain data into the frequency domain, capturing the frequency \n",
            "characteristics of the input data. In image processing, two-\n",
            "dimensional (2D) DCT is applied to transform a spatial-domain \n",
            "image (e.g., a 28√ó28 MNIST image) into its frequency spectrum, \n",
            "where the coefficients represent the energy distribution at different \n",
            "frequency components. Mathematically, the 2D DCT is defined as: \n",
            "ùêπùêπ(ùë¢ùë¢, ùë£ùë£) = ‚àë\n",
            "‚àë\n",
            "ùêºùêº(ùë•ùë•, ùë¶ùë¶)\n",
            "ùëÅùëÅ‚àí1\n",
            "ùë¶ùë¶=0\n",
            "ùëÅùëÅ‚àí1\n",
            "ùë•ùë•=0\n",
            "cos ·âÇ\n",
            "ùúãùúã(2ùë•ùë•+1)ùë¢ùë¢\n",
            "2ùëÅùëÅ\n",
            "·âÉcos ·âÇ\n",
            "ùúãùúã(2ùë¶ùë¶+1)ùë£ùë£\n",
            "2ùëÅùëÅ\n",
            "·âÉ, \n",
            "where ùêºùêº(ùë•ùë•, ùë¶ùë¶)  is the input image pixel value, and ùêπùêπ(ùë¢ùë¢, ùë£ùë£) \n",
            "represents the frequency coefficients after transformation. ùë¢ùë¢, ùë£ùë£ are \n",
            "the indices of the frequency components, and ùëÅùëÅ is the image \n",
            "dimension. \n",
            "The 2D DCT concentrates low-frequency components in the top-\n",
            "left corner of the transformed spectrum, while the high-frequency \n",
            "components spread towards the bottom-right corner. In our scheme, \n",
            "the upper triangular region of the 2D DCT spectrum is extracted, \n",
            "retaining only the most significant low-frequency features. This \n",
            "reduces the input data dimension while preserving essential \n",
            "information, thereby simplifying the computational complexity for \n",
            "the subsequent neural network processing.  \n",
            "B. Photonic synapse chip based on simplified MZI mesh. \n",
            "As shown in Fig. 1(b), we deployed the linear layer on a photonic \n",
            "synapse array chip to perform photonic linear computation. For this \n",
            "purpose, we designed and fabricated a chip based on a simplified \n",
            "MZI mesh on a silicon photonic platform to execute incoherent \n",
            "optical matrix-vector multiplication (MVM). The structure with a 16 \n",
            "√ó 16 MZI mesh are designed, where each MZI incorporates only a \n",
            "single phase shifter on one of its inner arms. For representing a 16 √ó \n",
            "16 weight matrix, the design utilizes 17 √ó (17-1)/2 + 16 = 152 phase \n",
            "shifters. Thus, this structure achieves significant area, transmission \n",
            "loss and power consumption reduction. The chip features a length of \n",
            "8.25 mm, a width of 2.37 mm, and a corresponding area of 19.55 \n",
            "mm2, with its microscopic image presented in Fig. 1(c). When light \n",
            "is injected through a single port, the chip demonstrates an \n",
            "approximate insertion loss of 13 decibels (dB). Equipped with 152 \n",
            "phase shifters (each featuring a half-wave phase shift power \n",
            "PœÄ=30mW), \n",
            "the \n",
            "total \n",
            "power \n",
            "consumption \n",
            "is \n",
            "about \n",
            "152√ó0.03W/2=2.28 W. \n",
            " \n",
            "C. Photonic nonlinear spiking neuron chip based on \n",
            "DFB-SA. \n",
            "As shown in Fig. 1(b), the LIF layer was deployed on a 16-channel \n",
            "DFB-SA laser array, fabricated on a III-V platform to enable \n",
            "element-wise nonlinear spike activation. As presented in Fig. 1(d), \n",
            "the array chip measures 4 mm in length and 0.3 mm in width, with a \n",
            "total area of 1.2 mm¬≤. Each single-channel DFB-SA laser within the \n",
            " \n",
            " \n",
            "Fig. 2. The epitaxial wafer structure and properties of DFB-SA laser. (a) The schematic of epitaxial wafer structure of DFB-SA laser. (b) \n",
            "Power current curve of DFB-SA laser. (c) The self-pulsation, frequency spectra of self-pulsation state and optical spectra of DFB-SA laser. \n",
            "array is structured with two sections, namely a gain region and a \n",
            "saturable absorber (SA) region. The gain region is forward-biased by \n",
            "a current source (IG), while the saturable absorber (SA) region is \n",
            "reverse-biased by a voltage source (VSA). The epitaxial wafer \n",
            "structure for single-channel DFB-SA laser unit is presented in Fig. \n",
            "2(a). The optimized multi-quantum well (MQW) structure \n",
            "comprises 7 well layers, and the thickness of the upper and lower \n",
            "confining layers is approximately 70 nm. Furthermore, anti-\n",
            "reflection (AR) coatings and high-reflection (HR) coatings are \n",
            "deposited on the two laser facets to boost the light emission power, \n",
            "while the SA region is placed close to the HR side. As shown in Fig. \n",
            "2(b), the measured lasing threshold is about 28 mA, and is almost the \n",
            "same for all the 16 DFB-SA lasers. The self-pulsation outputs, the \n",
            "corresponding frequency spectra and optical spectra for different IG \n",
            "and VSA are displayed in Fig. 2(c). The maximum self-pulsation \n",
            "frequency is measured to be about 5 GHz. When biasing slightly \n",
            "below the self-pulsation state, the nonlinear neuron-like response can \n",
            "be achieved [28], similar to our previous demonstration of single \n",
            "DFB-SA laser. The optical spectrum of the DFB-SA laser broadens \n",
            "when the device operates in the self-pulsation state. \n",
            " \n",
            "D. Experimental setup for testing the photonic \n",
            "neuromorphic computing system. \n",
            "The experimental setup of photonic neuromorphic computing \n",
            "system for deploying frequency-domain SNN is illustrated in Fig. 1 \n",
            "(e). Optical carriers with different wavelengths are generated by \n",
            "multi-channel TLs. The input signals for the photonic neuromorphic \n",
            "computing system were generated by a Xilinx FPGA platform, \n",
            "ZCU216 evaluation board, which features a Zynq UltraScale+ \n",
            "RFSoC 49DR chip and 16-channel high-speed AD/DA converters. \n",
            "The FPGA was controlled by a digital computer. The input signals \n",
            "were modulated into optical carriers by the Mach-Zehnder \n",
            "modulator (MZM). The modulated optical signal was then injected \n",
            "into the MZI mesh. The weights of the frequency-domain SNN were \n",
            "deployed on the MZI mesh, which was controlled through a multi-\n",
            "channel voltage source and a TEC for thermal stabilization. The \n",
            "modulated optical input signal was multiplied and added in the MZI \n",
            "mesh chip. To perform the nonlinear computation, the 16-channel \n",
            "output from the MZI mesh was fed into a 16-channel DFB-SA laser \n",
            "array. The output from the 16-channel DFB-SA laser array was \n",
            "routed through an array of three-port optical circulators. The \n",
            "resulting optical signals were then characterized using an optical \n",
            "spectrum analyzer and converted into electrical signals by a \n",
            "photodetector (Agilent/HP 11982A) for subsequent acquisition with \n",
            "an oscilloscope (Keysight DSOZ592A). \n",
            "3. Results \n",
            "A. Software-hardware collaborative training-inference \n",
            "framework. \n",
            "To tackle the challenges of SNN training difficulty and accuracy \n",
            "degradation in optical computing, we propose an end-to-end three-\n",
            "stage software-hardware-software collaborative training-inference \n",
            "framework tailored for frequency-domain photonic SNNs. Three \n",
            "sequential phases are incorporated into this framework, namely \n",
            "software pre-training phase, local photonic hardware in-situ training \n",
            "phase, and hardware-aware software fine-tuning phase. The \n",
            "complete workflow of the hardware-software integrated training and \n",
            "inference process is illustrated in Fig. 3. \n",
            "SNN pre-training. As shown in Fig. 3(a), the process begins with \n",
            "training an ANN, which is then converted to a SNN. Next, direct \n",
            "training of the SNN is performed using backpropagation based on \n",
            "surrogate gradients. Notably, a temporal pruning method is adopted \n",
            "to achieve low latency inference. This method treats the threshold \n",
            "and leakage of SNN as trainable parameters, initiating training with \n",
            "an SNN configured for T time steps and progressively reducing the \n",
            "time steps in each iteration, ultimately yielding an SNN with a single \n",
            "time step (T=1). In our implementation, the time steps of SNN are \n",
            "gradually compressed from 5 to 3, and finally to 1. We designate the \n",
            "software-trained weights requiring mapping to the hardware MZI \n",
            "chip as WS. The complete hybrid training algorithm, incorporating \n",
            "DCT, ANN-to-SNN conversion, direct training with surrogate \n",
            "gradient and temporal pruning, is summarized in Algorithm 1. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Fig. 3.  software-hardware-software collaborative training-inference framework for frequency-domain photonics SNNs. \n",
            "Algorithms 1. Single time step SNN training with DCT and temporal \n",
            "pruning \n",
            "Input: Input 28√ó28 MNIST image ùêºùêº, number of selected rows \n",
            "in spectrum diagram ùëÅùëÅùëüùëü, trained the SNN model with N time \n",
            "steps (\n",
            "N\n",
            "T\n",
            "), the time steps reduction step size b , number of \n",
            "epochs to train e . \n",
            "DCT Pre-processing: \n",
            "Apply DCT to ùêºùêº to obtain a 28√ó28 spectrum diagram ùêπùêπ. \n",
            "Extract the upper triangle region from the spectrum diagram \n",
            "using ùëÅùëÅùëüùëü: \n",
            "for each pixel ùêπùêπ(ùëñùëñ, ùëóùëó): \n",
            "Include pixel if ùëñùëñ+ ùëóùëó‚â§ùëÅùëÅùëüùëü‚àí1 \n",
            "// The size of input data for the network is \n",
            "ùëÅùëÅùëüùëü√ó(ùëÅùëÅùëüùëü+1)\n",
            "2\n",
            " \n",
            "Training with temporal pruning:  \n",
            "Train an ANN, new SNN initialized with trained parameters of \n",
            "N\n",
            "T\n",
            ", reduced latency \n",
            "rT\n",
            "N\n",
            "b\n",
            "=\n",
            "‚àí\n",
            " \n",
            "while ùëáùëáùëüùëü‚â•1 do \n",
            "   // Training Phase \n",
            "   for epoch 1: e  do \n",
            "      // Train network with ùëáùëáùëüùëü timesteps \n",
            "   end for \n",
            "   // Initialize another iso-architecture SNN with parameters of \n",
            "above trained network \n",
            "   // Temporal pruning \n",
            "   \n",
            "r\n",
            "r\n",
            "T\n",
            "T\n",
            "b\n",
            "=\n",
            "‚àí\n",
            " \n",
            "end while \n",
            " \n",
            "Local photonic hardware in-situ training. To represent the target \n",
            "weight matrix WS, the MZI mesh chip is configured using the \n",
            "stochastic parallel gradient descent (SPGD) algorithm based on local \n",
            "in-situ training [18]. This configuration strategy is due to the implicit \n",
            "nature of the optical matrix characterized by the MZI mesh. \n",
            "Specifically, there is no direct correspondence between one or more \n",
            "phase shifter heater voltages and a single element of the matrix. \n",
            "However, the weights trained on the hardware MZI chip may not \n",
            "perfectly match WS, as they are affected by noise, fabrication \n",
            "imperfections, and the limited precision of the multi-channel DACs \n",
            "that drive the phase shifters. The weight matrix represented by the \n",
            "trained MZI mesh is denoted as WH. \n",
            "The experiment setup for configuring MZI mesh chip is depicted \n",
            "in Fig. 3(b). Continuous wave is generated by a 16-channel TL \n",
            "source. A 16-channel TL source generates the CW input, while a 16-\n",
            "channel optical switch (OS) controls the injection sequence into the \n",
            "input ports of the MZI chip. Multi-channel voltage sources, \n",
            "controlled by a host computer, are used to adjust the weighting of the \n",
            "MZI. The output power of MZI chip is detected by the 16-channel \n",
            "optical power meters (PM) and than is feedback to the host computer. \n",
            "For the iterative update of MZI mesh weights, the SPGD algorithm \n",
            "is implemented to optimize the driving voltage of each phase shifter \n",
            "within the MZI mesh. The optimized voltages are then loaded onto \n",
            "the corresponding phase shifters by the host computer through \n",
            "regulating the multi-channel voltage sources via an Ethernet link. To \n",
            "mitigate the influence of temperature fluctuations on device \n",
            "performance, the operating temperature of the MZI mesh chip is \n",
            "actively stabilized at 25¬∞C by the TEC. \n",
            "The progress of the in-situ training for the MZI chip is illustrated \n",
            "in Fig. 3(e), which primarily consists of system initialization, weight \n",
            "matrix characterization, performance evaluation, gradient estimation \n",
            "via perturbation, and iterative optimization five key steps. \n",
            "‚ë†System initialization. A set of random voltages Ui is applied to \n",
            "the MZI phase shifters to initialize the MZI mash chip. \n",
            "‚ë°Weight matrix characterization. To characterize the weight \n",
            "matrix, CW light is first injected into a single input port. The optical \n",
            "power measured from the 16 output ports then forms one column of \n",
            "the matrix. This process is repeated by sequentially injecting light \n",
            "into each of the 16 input ports, ultimately constructing the complete \n",
            "16√ó16 hardware weight matrix WH1. \n",
            "‚ë¢Performance evaluation. The similarity J between the \n",
            "characterized hardware weight matrix WH1 and the target matrix WS \n",
            "is quantified using cosine similarity [18]. \n",
            "‚ë£Gradient estimation. The gradient is estimated by applying \n",
            "positive and negative voltage random perturbations (Ui+‚àÜui and Ui-\n",
            "‚àÜui), remeasuring the similarity metric (Jr and Jd), and computing the \n",
            "difference ‚àÜùêâùêâ=Jr - Jd. The phase shifter voltages are then updated \n",
            "by calculating the gradient based on ‚àÜùêâùêâ and ‚àÜui. \n",
            "‚ë§Iterative optimization. The phase shifter voltages are updated \n",
            "based on the calculated gradients, and steps 2-5 are repeated until the \n",
            "hardware weight matrix converges to the target.  \n",
            "Hardware-aware software fine-tuning stage. As shown \n",
            "in Fig. 3(c), the software-trained weights WS are substituted \n",
            "with their hardware-calibrated counterparts WH. During the \n",
            "subsequent fine-tuning stage, the weights corresponding to the MZI \n",
            "layer (WH) are fixed, while the remaining weights in the network are \n",
            "adjusted. This hardware-aware fine-tuning strategy ensures that the \n",
            "weights of the MZI layer are accurately represented by the physical \n",
            "chip, effectively compensating for inherent manufacturing variations \n",
            "and limitation of hardware. \n",
            "Hardware-software collaborative inference. As illustrated in \n",
            "Fig. 3(d), following the hardware-aware software fine-tuning stage, \n",
            "the converged weights WH and input spike signals are sent to the \n",
            "MZI chip for optical processing. The output of MZI is then fed into \n",
            "a DFBSA array to generate activated spikes (SpikeH). SpikeH are \n",
            "subsequently transmitted to the next software-based layer for further \n",
            "inference, with the aim of calculating accuracy.  \n",
            " \n",
            "B. MNIST and Fashion-MNIST classification using \n",
            "photonic neuromorphic chips.  \n",
            "We first consider a lightweight frequency-domain SNN with a size \n",
            "of 45√ó16√ó16√ó10 to classify the MNIST dataset. Specifically, after \n",
            "applying the DCT, we select only 45 low-frequency components for \n",
            "classification with frequency-domain SNN. The network comprises \n",
            "one input layer with 45 neurons, two hidden layers with 16 neurons \n",
            "each, and one output layer with 10 neurons. Such a small input layer \n",
            "size matches well with the fan-in number of an MZI mesh chip that \n",
            "can be fabricated using currently available silicon photonics process. \n",
            "In our experimental demonstration, the entire hidden layer with a \n",
            "size of 16√ó16 is deployed to the fabricated MZI mesh chip and the \n",
            "DFB-SA array chip. \n",
            " The pre-training and hardware-aware fine-tuning results are \n",
            "presented in Fig. 4(a). Here, the evolution of the training and testing \n",
            "accuracy and loss, as well as the confusion matrix are shown. We \n",
            "can find that the accuracy is 95.66% for ANN, 94.4% for SNN with \n",
            "T=5, 94.04% for SNN with T=3, 91.23% for SNN with T=1, and \n",
            "reaches 90.17% after performing hardware-aware fine-tuning. The \n",
            "hardware in-situ training results are presented in Fig. 4(b). It can be \n",
            "found that, even with only a single time step and with the input size \n",
            "of network reduced to only 45 (compared to 784 for conventional \n",
            "scheme), the accuracy maintains a relatively high value. Thus, this \n",
            "lightweight frequency-domain SNN with DCT closely matches the \n",
            "size of available photonic SNN chips, effectively bridging the gap \n",
            "between the network size and the integrated photonic chip scale. \n",
            "By deploying the weights to the MZI mesh chip, we measured the \n",
            "hardware linear computation and nonlinear spike activation results \n",
            "for 200 randomly selected test images for hardware and software \n",
            "inference. The experimentally measured results are presented in Fig. \n",
            "4(c). Here, the temporal results of two channels are displayed for \n",
            "simplicity. Clearly, the MZI mesh chip can perform linear MVM \n",
            " \n",
            "Fig. 4.  The results for the training and inference stage for MNIST datasets. (a) Accuracy and loss as functions of epoch, the test accuracy \n",
            "and confusion matrices for ANN training, SNN with T=5, SNN with T=3, SNN with T=1, and hardware-aware fine-tuning SNN with \n",
            "T=1, (b) Local in-situ training results including experimental and simulated accuracy as functions of epoch. (c) the experimentally measured \n",
            "linear computation and nonlinear spike activation results of two representative channels. \n",
            " \n",
            "Fig.5. The experimentally measured testing accuracy for (a) \n",
            "MNIST and (b) Fashion-MNIST dataset. \n",
            "function, and the DFB-SA laser array can accurately perform the \n",
            "nonlinear spike activation. Based on the neuron-like response of the \n",
            "DFB-SA laser, input pulses with relatively small amplitudes cannot \n",
            "trigger spike responses, and the nonlinear outputs become much \n",
            "sparser than the linear outputs. \n",
            "  The confusion matrix for the hardware chip inference for the \n",
            "MNIST dataset is presented in Fig. 5(a), and the hardware testing \n",
            "accuracy is 90%, which is slightly lower than 90.17% that achieved \n",
            "in the hardware-aware software fine-tuning stage, indicating that the \n",
            "proposed frequency-domain SNN is robust to fabrication errors and \n",
            "system noise. \n",
            "We also use the same frequency-domain SNN network structure \n",
            "and photonic neuromorphic computing chips to classify the Fashion-\n",
            "MNIST. The results of training accuracy and loss, confusion \n",
            " \n",
            " \n",
            "Fig.6.  The results for the training and inference stage for Fashion-MNIST dataset. (a) Accuracy and loss as functions of epoch, the test \n",
            "accuracy and confusion matrices for ANN training, SNN with T=5, SNN with T=3, SNN with T=1, and hardware-aware fine-tuning SNN \n",
            "with T=1. (b) Local in-situ training results including experimental and simulated accuracy as functions of epoch. (c) the experimentally \n",
            "measured linear computation and nonlinear spike activation results of two representative channels.  \n",
            "(b)\n",
            "(a)\n",
            "CH9\n",
            "CH11\n",
            "(c)\n",
            "matrices, as well as the photonic hardware in-situ training results can \n",
            "be found in Figs. 6 (a)-(b). We find that the accuracy is 85.57% for \n",
            "ANN, 84.45% for SNN with T=5, 84.35% for SNN with T=3, 81.23% \n",
            "for SNN with T=1, and 80.66% for hardware-aware fine-tuning \n",
            "SNN with T=1. The hardware linear and nonlinear computation \n",
            "temporal results for Fashion-MNIST can be found in Fig. 6 (c).  \n",
            "Correspondingly, as shown in Fig.5 (b), the hardware testing \n",
            "accuracy is 80.50% for the Fashion-MNIST dataset, and is slightly \n",
            "lower than 80.66% for software inference. \n",
            "We further consider numerical simulations to explore different \n",
            "network sizes. The numerical results for frequency-domain SNNs \n",
            "with size of 15√ó16√ó16√ó10 and 120√ó64√ó64√ó10 are presented for \n",
            "both datasets in Fig.7. For MNIST dataset, the accuracy for SNN \n",
            "with T=1 is 81.57% for the network size of 15√ó16√ó16√ó10, and is \n",
            "96.68% for the network size of 120√ó64√ó64√ó10. For the Fashion-\n",
            "MNIST, the accuracy for SNN with T=1 is 76.79% for the network \n",
            "size of 15√ó16√ó16√ó10, and is 86.56% for the network size of for \n",
            "120√ó64√ó64√ó10. The numerical findings validate the feasibility of \n",
            "enhancing the inference accuracy with larger-scale SNNs. \n",
            "4. DISCUSSION AND CONCLUSION \n",
            "Metrics. For PSNNs encompassing both linear and nonlinear \n",
            "computing, we evaluated the key performance metrics of the MZI \n",
            "mesh chip and the DFB-SA laser array chip, while accounting for \n",
            "the constraint relationship between them. Given that the DFB-SA \n",
            "laser array operates at the maximum self-pulsation frequency of 5 \n",
            "GHz, the signal rate of the MZI is correspondingly configured to 5 \n",
            "GHz. Under this operational parameter setting, the computing rate of \n",
            "the MZI chip is calculated as 2 √ó 16 √ó 16 √ó 5 GHz, yielding a value \n",
            "of 2.5 TOPS. Leveraging the metrics of the area and total power \n",
            "consumption of chip, we calculated its energy efficiency at 1.39 \n",
            "TOPS/W and computing density at 0.13 TOPS/mm¬≤. As for the 16-\n",
            "channel DFB-SA laser array chip, its throughput is calculated as 640 \n",
            "GOPS, considering that each input undergoes 8 equivalent \n",
            "operations when emulating the LIF neuron, with the formulation \n",
            "being 16√ó8√ó5 GHz. With a total energy consumption of \n",
            "approximately 0.648 W, the chip achieves an energy efficiency of \n",
            "987.65 GOPS/W and a computing density of 533.33 GOPS/mm¬≤. \n",
            "The end-to-end latency for implementing a full layer of the SNN, \n",
            "including both photonic MVM and photonic LIF modules, is \n",
            "calculated as 320 ps. Table 1 presents a comparative analysis of our \n",
            "chips against state-of-the-art PNN chips including optical nonlinear \n",
            "computation and electronic neuromorphic chips. To the best of our \n",
            "knowledge, among previously reported PNN chips capable of \n",
            "supporting optical nonlinear computing, our design is superior to \n",
            "counterparts in energy efficiency, computing density, and the \n",
            "number of trainable parameters three critical dimensions. \n",
            "Scalability. Notably, the photonic spiking neurons based on the \n",
            "DFB-SA laser array exhibit excellent scalability. They can be readily \n",
            "expanded to 150 channels while maintaining high wavelength \n",
            "precision [64]. For the MZI mesh architecture, prior work has already \n",
            "demonstrated the feasibility of large-scale integration. Specifically, a \n",
            "128√ó128 integrated photonic arithmetic computing engine has been \n",
            "successfully implemented for optical Ising model applications [20]. \n",
            "Building on this precedent, our proposed simplified MZI mesh \n",
            "design enables scalable expansion to a 128√ó128 configuration with \n",
            "manageable loss levels. Furthermore, advanced heterogeneous \n",
            "integration technologies offer the potential to achieve even tighter \n",
            "integration of photonic synapse chips and photonic spiking neuron \n",
            "chips, laying the groundwork for higher-performance monolithic \n",
            "systems. \n",
            "All-optical DCT potential. DCT encoding, a well-established \n",
            "and efficient image processing technique, can be inherently \n",
            "implemented in diffractive neural networks relying on optical \n",
            "passive devices [65]. Looking ahead, integration with this all-optical \n",
            "DCT paradigm could empower all-optical pattern classification to \n",
            "enable pattern preprocessing and recognition without the need for \n",
            "EO/OE conversions. This integration would leverage inherent \n",
            "optical signal processing capabilities of the system, achieving \n",
            "remarkable low latency and superior energy efficiency. \n",
            "Table 1. Comparison with state-of-the-art photonic neural network chips and electronic neuromorphic chips \n",
            "Metrics \n",
            "Computing density \n",
            " \n",
            "Energy efficiency \n",
            "Trainable parameters \n",
            "Optical nonlinear computation \n",
            "For SNN \n",
            "Our work \n",
            "0.13 TOPS/mm2 \n",
            "1.39 TOPS/W \n",
            "272 \n",
            "‚àö  \n",
            "‚àö \n",
            "Ashtiani et al [15] \n",
            "1.75 TOPS/mm2 \n",
            "2.9 TOPS/W \n",
            "67 \n",
            "‚àö \n",
            "X \n",
            "Bandyopadhyay et al [17]  0.02 TOPS/mm2 \n",
            "0.013 TOPS/W \n",
            "132 \n",
            "‚àö  \n",
            "X \n",
            "Feldmann et al [28]  \n",
            "N/A \n",
            "N/A \n",
            "64 \n",
            "‚àö  \n",
            "‚àö \n",
            "Fang et al [19]  \n",
            "0.23 TOPS/mm2 \n",
            "N/A \n",
            "N/A \n",
            "‚àö \n",
            "‚àö \n",
            "Dong et al [20]  \n",
            "N/A \n",
            "121.7 pJ/OP \n",
            "N/A \n",
            "‚àö \n",
            "X \n",
            "Tianjic [62]  \n",
            "84.08 GOPS/mm2 \n",
            "1278 GOPS/W \n",
            "N/A \n",
            "N/A \n",
            "‚àö \n",
            "NVIDIA H100 [63]  \n",
            "N/A \n",
            "0.15 TOPS/W \n",
            "N/A \n",
            "N/A \n",
            "X \n",
            "Fig.7. SNN pre-training results for (a) MNIST and (b) Fashion-\n",
            "MNIST dataset with a size of 15√ó16√ó16√ó10. SNN pre-training \n",
            "results for (c) MNIST and (d) Fashion-MNIST dataset with a \n",
            "size of 120√ó64√ó64√ó10. \n",
            "Conclusion. In summary, we present a programmable incoherent \n",
            "photonic neuromorphic computing chip equipped with 272 trainable \n",
            "model parameters, which supports the full deployment of a SNN \n",
            "layer. A core strength of this chip lies in its capability to execute both \n",
            "linear and nonlinear spike computations directly within the optical \n",
            "domain, eliminating the need for frequent optical-to-electrical \n",
            "conversion and thereby laying the foundation for high-efficiency \n",
            "computing. \n",
            "Our design incorporates two specialized components with notable \n",
            "performance merits. First, the photonic synapse chip benefits from a \n",
            "simplified architecture that delivers low loss, low power \n",
            "consumption, and a compact footprint. Second, the photonic spiking \n",
            "neuron array chip achieves a low lasing threshold and small form \n",
            "factor through an optimized epitaxial wafer structure.  \n",
            "To address the inherent challenges of SNN training and enhance \n",
            "the accuracy and robustness of photonic SNNs, we further \n",
            "developed a software-hardware collaborative training-inference \n",
            "framework. This framework integrates software pre-training, \n",
            "photonic hardware in-situ training, and hardware-aware software \n",
            "fine-tuning, and this approach is generalizable to all photonic SNN \n",
            "hardware architectures. By introducing DCT for input data \n",
            "dimension reduction, we realized a high-performance lightweight \n",
            "frequency-domain SNN operating at a single time step (T=1). \n",
            "Hardware testing validated its effectiveness, achieving 90% \n",
            "accuracy on the MNIST dataset and 80.5% accuracy on the Fashion-\n",
            "MNIST dataset.  \n",
            "Compared with state-of-the-art PNN chips capable of supporting \n",
            "optical nonlinear computation, our work exhibits distinct advantages \n",
            "including high energy efficiency (1.39 TOPS/W for linear \n",
            "computations and 987.65 GOPS/W for nonlinear computations), \n",
            "high computing density (0.13 TOPS/mm2 for linear computations \n",
            "and 533.33 GOPS/mm¬≤ for nonlinear computations), and low \n",
            "latency (320 ps). Overall, our research addresses two critical \n",
            "challenges including the lack of large-scale photonic nonlinear spike \n",
            "computation capabilities and the difficulty of training photonic \n",
            "SNNs. This work thus paves a promising path for the development \n",
            "of fully functional photonic SNN chips. \n",
            "References  \n",
            "1. \n",
            "G. Wetzstein et al., ‚ÄúInference in artificial intelligence with deep optics \n",
            "and photonics,‚Äù Nature 588, 39‚Äì47 (2020).  \n",
            "2. \n",
            "B. J. Shastri et al., ‚ÄúPhotonics for artificial intelligence and \n",
            "neuromorphic computing,‚Äù Nature Photon. 15, 102‚Äì114 (2021). \n",
            "3. \n",
            "K. Liao, et al. ‚ÄúAll-optical computing based on convolutional neural \n",
            "networks,‚Äù Opto-Electron Adv 4, 200060 (2021). \n",
            "4. \n",
            "H. Zhou et al., ‚ÄúPhotonic matrix multiplication lights up photonic \n",
            "accelerator and beyond,‚Äù Light Sci. Appl. 11, 30 (2022).   \n",
            "5. \n",
            "C. Huang et al., ‚ÄúProspects and applications of photonic neural \n",
            "networks,‚Äù Adv. Phys. X 7, 1981155 (2022).  \n",
            "6. \n",
            "C. Li, et al. ‚ÄúPhotonic synapses with ultralow energy consumption for \n",
            "artificial visual perception and brain storage,‚Äù Opto-Electron Adv 5, \n",
            "210069 (2022). \n",
            "7. \n",
            "A. Zhao, N. Jiang, J. Peng, S. Liu, Y. Zhang, K. Qiu, ‚ÄúParallel \n",
            "generation of low-correlation wideband complex chaotic signals using \n",
            "CW laser and external-cavity laser with self-phase-modulated \n",
            "injection,‚Äù Opto-Electronic Advances, 5: 200026 (2022). \n",
            "8. \n",
            "T. Fu, J. Zhang, R. Sun et al., ‚ÄúOptical neural networks: progress and \n",
            "challenges,‚Äù Light Sci. Appl. 13, 263 (2024). \n",
            "9. \n",
            "C. Zhou et al. ‚ÄúStreamlined photonic reservoir computer with \n",
            "augmented memory capabilities,‚Äù Opto-Electron Adv 8, 240135 \n",
            "(2025). \n",
            "10. \n",
            "Y. Wang et al., ‚ÄúAsymmetrical estimator for training encapsulated deep \n",
            "photonic neural networks,‚Äù Nat. Commun. 16, 2143 (2025). \n",
            "11. \n",
            "T. Yan, et al., ‚ÄúA complete photonic integrated neuron for nonlinear \n",
            "all-optical computing,‚Äù Nat Comput. Sci. (2025). \n",
            "12. \n",
            "T. Yang, et al. ‚ÄúSpatiotemporal multiplexed photonic reservoir \n",
            "computing: parallel prediction for the high-dimensional dynamics of \n",
            "complex semiconductor laser network,‚Äù Opto-Electron Adv 8, 250159 \n",
            "(2025).  \n",
            "13. \n",
            "Y. Shen et al., ‚ÄúDeep learning with coherent nanophotonic circuits,‚Äù \n",
            "Nature Photon. 11, 441‚Äì446 (2017). \n",
            "14. \n",
            "Y. Tian, Y. Zhao, S. Liu, Q. Li, W. Wang, J. Feng and J. Guo, ‚ÄúScalable \n",
            "and compact photonic neural chip with low learning-capability-loss‚Äù, \n",
            "Nanophotonics 11, 329‚Äì344 (2022). \n",
            "15. \n",
            "F. Ashtiani, A.J. Geers and F.A. Aflatouni, ‚ÄúAn on-chip photonic deep \n",
            "neural network for image classification‚Äù, Nature 606, 501‚Äì506 (2022). \n",
            "16. \n",
            "B. Peng, S. Hua, Z. Su, Y. Xu, Y. Shen, ‚ÄúA 64√ó64 integrated photonic \n",
            "accelerator‚Äù, 2022 IEEE Photonics Conference (IPC). \n",
            "17. \n",
            "S. Bandyopadhyay, A. Sludds, S. Krastanov et al., ‚ÄúSingle-chip \n",
            "photonic deep neural network with forward-only training‚Äù, Nat. \n",
            "Photon. 18, 1335‚Äì1343 (2024). \n",
            "18. \n",
            "Y. Wan, X. Liu, G. Wu, M. Yang, G. Yan, Y. Zhang and J. Wang, \n",
            "‚ÄúEfficient stochastic parallel gradient descent training for on-chip \n",
            "optical processor‚Äù, Opto-Electron Adv 7, 230182 (2024). \n",
            "19. \n",
            "Z. Xue, T. Zhou, Z. Xu et al., ‚ÄúFully forward mode training for optical \n",
            "neural networks‚Äù, Nature 632, 280‚Äì286 (2024). \n",
            "20. \n",
            "B. Wu, et al. ‚ÄúScaling up for end-to-end on-chip photonic neural \n",
            "network inference,‚Äù Light-Sci. 14,328 (2025). \n",
            "21. \n",
            "J. Ouyang, S. Liu, Z. Yang, W. Wang, X. Feng, Y. Li, Y. Huang, ‚Äú16-\n",
            "channel photonic solver for optimization problems on a silicon chip‚Äù, \n",
            "Chip, 4, 100117 (2025). \n",
            "22. \n",
            "S. Hua, et al., ‚ÄúAn integrated large-scale photonic accelerator with \n",
            "ultralow latency‚Äù, Nature 640, 361‚Äì367 (2025). \n",
            "23. \n",
            "S.R. Ahmed, et al., ‚ÄúUniversal photonic artificial intelligence \n",
            "acceleration‚Äù, Nature 640, 368‚Äì374 (2025). \n",
            "24. \n",
            "A.N. Tait et al., ‚ÄúNeuromorphic photonic networks using silicon \n",
            "photonic weight banks‚Äù, Sci. Rep. 7, 1-10 (2017). \n",
            "25. \n",
            "S. Ohno, R. Tang, K. Toprasertpong et al., ‚ÄúSi microring resonator \n",
            "crossbar array for on-chip inference and training of the optical neural \n",
            "network‚Äù, ACS Photon. 9, 2614‚Äì2622 (2022). \n",
            "26. \n",
            "T. Xu, et al, ‚ÄúControl-free and efficient integrated photonic neural \n",
            "networks via hardware-aware training and pruning‚Äù, Optica 11, 1039-\n",
            "1049 (2024). \n",
            "27. \n",
            "S Jiang, et al. ‚ÄúMRR‚Äêassisted MZI crossbar array for energy‚Äêefficient \n",
            "optical parallel computing,‚Äù Laser Photonics Rev., 11: e01035 (2025). \n",
            "28. \n",
            "J. Feldmann, N. Youngblood, C.D. Wright, H. Bhaskaran, W.H. \n",
            "Pernice, ‚ÄúAll-optical spiking neurosynaptic networks with self-\n",
            "learning capabilities‚Äù, Nature 569, 208-214 (2019). \n",
            "29. \n",
            "W. Zhou, et al. ‚ÄúIn-memory photonic dot-product engine with \n",
            "electrically programmable weight banks‚Äù, Nat. Commun. 14, 2887 \n",
            "(2023). \n",
            "30. \n",
            "M. Wei, et al., ‚ÄúMonolithic back-end-of-line integration of phase \n",
            "change materials into foundry-manufactured silicon photonics‚Äù, Nat \n",
            "Commun. 15, 2786 (2024). \n",
            "31. \n",
            "M.A. Nahmias, B.J. Shastri, A.N. Tait and P.R. Prucnal, ‚ÄúA leaky \n",
            "integrate-and-fire laser neuron for ultrafast cognitive computing‚Äù, \n",
            "IEEE J. Sel. Top. Quantum Electron. 19, 1-12 (2013). \n",
            "32. \n",
            "P. R. Prucnal, B.J. Shastri, T.F. de Lima and M.A. Nahmias, ‚ÄúRecent \n",
            "progress in semiconductor excitable lasers for photonic spike \n",
            "processing‚Äù, Adv. Opt. Photonics 8, 228-299 (2016). \n",
            "33. \n",
            "H.T. Peng et al., ‚ÄúTemporal information processing with an integrated \n",
            "laser neuron‚Äù, IEEE J. Sel. Top. Quantum Electron. 26, 5100209 \n",
            "(2020). \n",
            "34. \n",
            "X. Guo, J. Xiang, Y. Zhang and Y. Su, ‚ÄúIntegrated neuromorphic \n",
            "photonics: synapses, neurons, and neural networks‚Äù, Adv. Photonics \n",
            "Res. 2, 2000212 (2021). \n",
            "35. \n",
            "S. Xiang et al., ‚ÄúComputing primitive of fully-VCSELs-based all-\n",
            "optical spiking neural network for supervised learning and pattern \n",
            "classification‚Äù, IEEE Trans. Neural Netw. Learn. Syst. 32, 2494‚Äì2505 \n",
            "(2021). \n",
            "36. \n",
            "Y. Zhang, S. Xiang, C. Yu, S. Gao, Y. Han, X. Guo, Y. Zhang, Y. Shi \n",
            "and Y. Hao, ‚ÄúPhotonic neuromorphic pattern recognition with a spiking \n",
            "DFB-SA laser subject to incoherent optical injection‚Äù, Laser Photonics \n",
            "Rev., 2400482, (2024). \n",
            "37. \n",
            "X. Guo, et al. ‚ÄúFour‚Äêchannel full‚Äêfunction photonic spiking neural \n",
            "network chips for gene analysis,‚Äù Laser Photonics Rev., e00864 (2025). \n",
            "38. \n",
            "M. Y.-S. Fang, S. Manipatruni, C. Wierzynski, A. Khosrowshahi, and \n",
            "M. R. DeWeese, ‚ÄúDesign of optical neural networks with component \n",
            "imprecisions,‚Äù Opt. Exp., 27(10) :14009‚Äì14029 (2019). \n",
            "39. \n",
            "F. Dai, Y. Chen, Z. Huang, H. Zhang, H. Zhang, and C. Xia. \n",
            "‚ÄúComparing the performance of multi-layer perceptron training on \n",
            "electrical \n",
            "and \n",
            "optical \n",
            "network-on-chips,‚Äù \n",
            "The \n",
            "Journal \n",
            "of \n",
            "supercomputing, 10: 10725-10746 (2022). \n",
            "40. \n",
            "J. Feldmann et al., ‚ÄúParallel convolutional processing using an \n",
            "integrated photonic tensor core,‚Äù Nature 589, 52‚Äì58 (2021). \n",
            "41. \n",
            "X. Xu et al., ‚Äú11 TOPS photonic convolutional accelerator for optical \n",
            "neural networks,‚Äù Nature 589, 44‚Äì51 (2021). \n",
            "42. \n",
            "X. Meng, et al., ‚ÄúCompact optical convolution processing unit based \n",
            "on multimode interference,‚Äù Nat. Commun. 14, 3000 (2023). \n",
            "43. \n",
            "B. Bai et al., ‚ÄúMicrocomb-based integrated photonic processing unit,‚Äù \n",
            "Nat. Commun. 14, 66 (2023). \n",
            "44. \n",
            "S. Xu et al., ‚ÄúOptical coherent dot-product chip for sophisticated deep \n",
            "learning regression,‚Äù Light Sci. Appl. 10, 1‚Äì12 (2021).  \n",
            "45. \n",
            "B. Dong et al., ‚ÄúHigher-dimensional processing using a photonic \n",
            "tensor core with continuous-time data,‚Äù Nat. Photonics 17, 1080‚Äì1088 \n",
            "(2023). \n",
            "46. \n",
            "S. Xu, J. Wang, S. Yi, and W. Zou, ‚ÄúHigh-order tensor flow processing \n",
            "using integrated photonic circuits,‚Äù Nat. Commun. 13, 7970 (2022). \n",
            "47. \n",
            "Z. Lin, B. J. Shastri, S. Yu et al., ‚Äú120 GOPS photonic tensor core in \n",
            "thin-film lithium niobate for inference and in situ training,‚Äù Nat. \n",
            "Commun. 15, 9081 (2024).  \n",
            "48. \n",
            "S. Ning, H. Zhu, C. Feng, J. Gu, D. Z. Pan, and Ray T. Chen. \n",
            "‚ÄúHardware-efficient photonic tensor core: accelerating deep neural \n",
            "networks with structured compression.‚Äù Optica, 12(7): 1079-1089 \n",
            "(2025). \n",
            "49. \n",
            "X. Lin, Y. Rivenson, N. T. Yardimei, M. Veli et al., ‚ÄúAll-optical \n",
            "machine learning using diffractive deep neural networks,‚Äù Science 361, \n",
            "1004‚Äì1008 (2018). \n",
            "50. \n",
            "H. H. Zhu, J. Zou, H. Zhang et al., ‚ÄúSpace-efficient optical computing \n",
            "with an integrated chip diffractive neural network,‚Äù Nat. Commun. 13, \n",
            "1044 (2022). \n",
            "51. \n",
            "T. Fu et al., ‚ÄúPhotonic machine learning with on-chip diffractive optics,‚Äù \n",
            "Nat. Commun. 14, 70 (2023).  \n",
            "52. \n",
            "Z. Zheng, et al., ‚ÄúDual adaptive training of photonic neural networks,‚Äù \n",
            "Nat. Mach. Intell. 5, 1119‚Äì1129 (2023). \n",
            "53. \n",
            "J. Cheng, C. Huang, J. Zhang et al., ‚ÄúMultimodal deep learning using \n",
            "on-chip diffractive optics with in situ training capability,‚Äù Nat. \n",
            "Commun. 15, 6189 (2024). \n",
            "54. \n",
            ", H. Chen, S. Lou, Q. Wang, P. Huang, H. Duan, and Y. Hu. ‚ÄúDiffractive \n",
            "deep neural networks: theories, optimization, and applications,‚Äù App. \n",
            "Phys. Rev. 11(2): 021332 (2024). \n",
            "55. \n",
            "Y. Zhang, et al. ‚ÄúDirect tensor processing with coherent light,‚Äù Nat. \n",
            "Photonics, Published online, (2025). \n",
            "56. \n",
            "A. Jha, C. Huang, H.-T. Peng, B. Shastri, and P. R. Prucnal, ‚ÄúPhotonic \n",
            "spiking neural networks and graphene-on-silicon spiking neurons,‚Äù J. \n",
            "Lightwave Technol. 40, 2901‚Äì2914 (2022).   \n",
            "57. \n",
            "S. Xiang, Y. Shi, X. Guo, Y. Zhang, H. Wang, D. Zheng, Z. Song, Y. \n",
            "Han, S. Gao, S. Zhao, B. Gu, H. Wang, X. Zhu, L. Hou, X. Chen, W. \n",
            "Zheng, X. Ma, and Y. Hao, ‚ÄúHardware-algorithm collaborative \n",
            "computing with photonic spiking neuron chip based on integrated \n",
            "Fabry‚ÄìPerot laser with saturable absorber,‚Äù Optica 10, 162‚Äì171 (2023).   \n",
            "58. \n",
            "S. Y. Xiang, Y. C. Shi, Y. H. Zhang, X. X. Guo et al., ‚ÄúPhotonic \n",
            "integrated neuro-synaptic core for convolutional spiking neural \n",
            "network,‚Äù Opto-Electron. Adv. 6, 230140 (2023).   \n",
            "59. \n",
            "S. Xiang et al., ‚ÄúSemiconductor lasers for photonic neuromorphic \n",
            "computing and photonic spiking neural networks: A perspective,‚Äù APL \n",
            "Photonics 9, 070903 (2024). \n",
            "60. \n",
            "S. Xiang et al., ‚ÄúNonlinear Photonic Neuromorphic Chips for Spiking \n",
            "Reinforcement Learning‚Äù, arXiv, (2025). https://doi.org/10.48550/ \n",
            "arXiv.2508.06962 \n",
            "61. \n",
            "V. Britanak, P. Yip, and K. R. Rao, Discrete Cosine and Sine \n",
            "Transforms (New York: Academic, 2007). \n",
            "62. \n",
            "J. Pei et al., ‚ÄúTowards artificial general intelligence with hybrid Tianjic \n",
            "chip architecture,‚Äù Nature 572, 106‚Äì111 (2019).  \n",
            "63. \n",
            "NVIDIA, ‚ÄúNVIDIA H100 Tensor Core GPU Datasheet,‚Äù (2024). \n",
            "[Online]. \n",
            "Available: \n",
            "https://resources.nvidia.com/en-us-tensor-\n",
            "core/nvidia-tensor-core-gpu-datasheet. \n",
            "64. \n",
            "Y. Zhang, Z. Sun, R. Xiao, X. Chen, ‚ÄúExperimental demonstration of \n",
            "150-channel REC-DFB laser array based on asymmetric multiple-\n",
            "quantum-well,‚Äù IEEE J. Quantum Electron. 61(3): 2200307 (2025). \n",
            "65. \n",
            "H. Ren, Y. Feng, S. Zhou, D. Wang, X. Yang, and S. Chen. ‚ÄúAll-optical \n",
            "DCT encoding and information compression based on diffraction \n",
            "neural network.‚Äù ACS photonics, 12:1196 ‚Äì 1211 (2025). \n",
            " \n",
            "Acknowledgements  \n",
            "We are grateful for financial supports from the National Natural Science Foundation of China \n",
            "(No.62535015, 62575231); The Fundamental Research Funds for the Centrale Universities \n",
            "(QTZX23041). \n",
            " \n",
            "Author contributions \n",
            "S. Y. Xiang and Y. H. Zhang are co-first authors of the article. S. Y. Xiang proposed the idea, \n",
            "S. Y. Xiang, Y. H. Zhang prepared the manuscript, S. X. Shi, H. W. Zhao, D. Z. Zheng \n",
            "performed system experiments, Y. H. Zhang, X. X. Guo tested the chips, Y. N. Han, Y. Tian, \n",
            "L. Y. Zhang developed the algorithms, Y. C. Shi fabricated the samples, S. Y. Xiang, Y. Hao \n",
            "supervised the overall projects. All the authors analyzed and discussed the results. \n",
            " \n",
            "Competing interests \n",
            "The authors declare no competing financial interests. \n",
            " \n",
            "Data availability.  \n",
            "The example dataset used in this paper are publicly available and can be accessed at \n",
            "https://yann.lecun.com/exdb/mnist/ \n",
            "for \n",
            "MNIST \n",
            "dataset, \n",
            "and \n",
            "https://github.com/zalandoresearch/fashion-mnist for fashion-MNIST dataset. Other data that \n",
            "support the findings of this study are available from the corresponding author upon reasonable \n",
            "request. \n",
            " \n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'Page \\d+', '', text)\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "3Nvy7fiMRdLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SECTIONS = [\n",
        "    \"abstract\",\n",
        "    \"introduction\",\n",
        "    \"related work\",\n",
        "    \"methodology\",\n",
        "    \"methods\",\n",
        "    \"experiments\",\n",
        "    \"results\",\n",
        "    \"conclusion\"\n",
        "]\n",
        "\n",
        "def detect_sections(text):\n",
        "    sections = {}\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    for i, sec in enumerate(SECTIONS):\n",
        "        start = text_lower.find(sec)\n",
        "        if start == -1:\n",
        "            continue\n",
        "\n",
        "        end = len(text)\n",
        "        for next_sec in SECTIONS[i+1:]:\n",
        "            pos = text_lower.find(next_sec, start + 1)\n",
        "            if pos != -1:\n",
        "                end = pos\n",
        "                break\n",
        "\n",
        "        sections[sec] = text[start:end].strip()\n",
        "\n",
        "    return sections\n"
      ],
      "metadata": {
        "id": "dVJvRwsERhO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KEYWORDS = [\n",
        "    \"propose\", \"introduce\", \"improve\",\n",
        "    \"results show\", \"outperform\", \"significant\"\n",
        "]\n",
        "\n",
        "def extract_key_findings(text, limit=5):\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "    findings = []\n",
        "\n",
        "    for s in sentences:\n",
        "        if any(k in s.lower() for k in KEYWORDS):\n",
        "            findings.append(s)\n",
        "        if len(findings) == limit:\n",
        "            break\n",
        "\n",
        "    return findings\n"
      ],
      "metadata": {
        "id": "2QMh6mFYRjew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_findings = {}\n",
        "\n",
        "for pdf in os.listdir(\"data/pdfs\"):\n",
        "    if not pdf.endswith(\".pdf\"):\n",
        "        continue\n",
        "\n",
        "    print(\"Processing:\", pdf)\n",
        "    path = f\"data/pdfs/{pdf}\"\n",
        "\n",
        "    raw = extract_text_from_pdf(path)\n",
        "    clean = clean_text(raw)\n",
        "\n",
        "    # Save full text\n",
        "    with open(f\"data/extracted_text/{pdf}.json\", \"w\") as f:\n",
        "        json.dump({\"text\": clean}, f, indent=4)\n",
        "\n",
        "    sections = detect_sections(clean)\n",
        "\n",
        "    # Save sections\n",
        "    with open(f\"data/structured_sections/{pdf}_sections.json\", \"w\") as f:\n",
        "        json.dump(sections, f, indent=4)\n",
        "\n",
        "    all_findings[pdf] = extract_key_findings(clean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJGrV-sNRmdN",
        "outputId": "21da6429-fbfc-4e11-a5e0-225d51a24d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: 2512.19182v1.pdf\n",
            "Processing: 2512.00427v1.pdf\n",
            "Processing: 2512.00419v1.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter()\n",
        "\n",
        "for paper, findings in all_findings.items():\n",
        "    for sentence in findings:\n",
        "        counter.update(sentence.lower().split())\n",
        "\n",
        "common_words = counter.most_common(15)\n",
        "\n",
        "with open(\"data/comparisons/comparison.json\", \"w\") as f:\n",
        "    json.dump(common_words, f, indent=4)\n",
        "\n",
        "common_words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5N1EbnqRoxC",
        "outputId": "967af7c4-8688-4d90-ae6f-2a5a62fe151f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 23),\n",
              " ('of', 14),\n",
              " ('and', 11),\n",
              " ('photonic', 10),\n",
              " ('neural', 9),\n",
              " ('spiking', 8),\n",
              " ('a', 8),\n",
              " ('to', 8),\n",
              " ('architecture', 7),\n",
              " ('proposed', 6),\n",
              " ('on', 6),\n",
              " ('in', 6),\n",
              " ('an', 5),\n",
              " ('network', 5),\n",
              " ('we', 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2xlrLaenRrTU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}