# -*- coding: utf-8 -*-
"""internship 6.0

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QOrUCpm4OjPMYNyMlc6b7YEqa6NPjyEW
"""

# MODULE 1: Topic Input & Paper Search

!pip install semanticscholar python-dotenv requests tabulate pandas -q

import json
import os
import pandas as pd
from tabulate import tabulate
from semanticscholar import SemanticScholar
from dotenv import load_dotenv


# 0. CREATE PROJECT FOLDER STRUCTURE

def create_project_folders():
    folders = [
        "data",
        "data/search_results",
        "data/raw_pdfs",
        "data/metadata"
    ]
    for folder in folders:
        os.makedirs(folder, exist_ok=True)
    print("üìÅ Project folders verified/created.")



# 1. SETUP API KEY

def setup_api_key():
    load_dotenv()
    API_KEY = os.getenv("SEMANTIC_SCHOLAR_API_KEY")

    if not API_KEY:
        print("‚ö† No API key found. Running with LIMITED API rate.")
        sch = SemanticScholar()
    else:
        print("üîë API Key loaded successfully.")
        sch = SemanticScholar(api_key=API_KEY)

    return sch



# 2. SEARCH PAPERS (WITH FILTERS)

def search_papers(topic, limit=20, year_filter=None, open_access_only=False):
    sch = setup_api_key()

    print(f"\nüîé Searching for papers on: '{topic}'")
    print(f"üì° Requesting {limit} papers from Semantic Scholar...")

    try:
        results = sch.search_paper(
            query=topic,
            limit=limit,
            fields=[
                "paperId", "title", "abstract", "year", "authors",
                "citationCount", "openAccessPdf", "url", "venue"
            ]
        )

        papers = []

        for paper in results:
            # Apply filters
            if year_filter and paper.year != year_filter:
                continue
            if open_access_only and not paper.openAccessPdf:
                continue

            papers.append({
                "paperId": paper.paperId,
                "title": paper.title,
                "authors": [a["name"] for a in paper.authors] if paper.authors else [],
                "year": paper.year,
                "abstract": (paper.abstract[:300] + "...") if paper.abstract else "No abstract available",
                "citationCount": paper.citationCount,
                "venue": paper.venue,
                "url": paper.url,
                "pdf_url": paper.openAccessPdf["url"] if paper.openAccessPdf else None,
                "has_pdf": bool(paper.openAccessPdf)
            })

        print("\nüìä Search Completed!")
        print(f"   ‚û§ Total papers after filters: {len(papers)}")
        print(f"   ‚û§ Papers with PDF: {sum(x['has_pdf'] for x in papers)}")

        return {
            "topic": topic,
            "total_results": len(papers),
            "papers": papers
        }

    except Exception as e:
        print(f"‚ùå Error during search: {e}")
        return None


# 3. SAVE RESULTS TO JSON + CSV

def save_search_results(data):
    topic_clean = data["topic"].replace(" ", "_")
    json_path = f"data/search_results/{topic_clean}.json"
    csv_path = f"data/search_results/{topic_clean}.csv"

    # JSON Save
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4, ensure_ascii=False)
    print(f"üíæ JSON saved to: {json_path}")

    # CSV Save
    df = pd.DataFrame(data["papers"])
    df.to_csv(csv_path, index=False)
    print(f"üìä CSV saved to: {csv_path}")

    return json_path, csv_path



# 4. SUMMARY TABLE VIEW

def display_search_results(data):
    papers = data["papers"]

    print("\n" + "="*90)
    print(f"SEARCH SUMMARY: {data['topic']}")
    print("="*90)

    print(f"\nüìå Total Papers: {len(papers)}")
    print(f"üìå Papers with PDF: {sum(p['has_pdf'] for p in papers)}")
    print(f"üìå Papers without PDF: {sum(not p['has_pdf'] for p in papers)}")

    table_data = []
    for p in papers[:10]:  # Show only top 10
        table_data.append([
            p["title"][:40] + ("..." if len(p["title"]) > 40 else ""),
            p["year"],
            p["citationCount"],
            "Yes" if p["has_pdf"] else "No"
        ])

    print("\nüìù TOP PAPERS TABLE:")
    print(tabulate(table_data, headers=["Title", "Year", "Citations", "PDF"], tablefmt="pretty"))


# 5. MAIN SEARCH FLOW

def main_search():
    create_project_folders()

    print("\n" + "="*80)
    print(" MODULE 1: TOPIC INPUT & PAPER SEARCH")
    print("="*80)

    topic = input("\nEnter research topic: ").strip()
    if not topic:
        topic = "machine learning"

    # Optional filters
    year_input = input("Filter by year? (Press Enter to skip): ").strip()
    year_filter = int(year_input) if year_input.isdigit() else None

    oa_input = input("Open access only? (y/n): ").lower().strip()
    open_access_only = oa_input == "y"

    # SEARCH
    results = search_papers(
        topic,
        limit=20,
        year_filter=year_filter,
        open_access_only=open_access_only
    )

    if not results or results["total_results"] == 0:
        print("\n‚ùå No papers found. Try a different topic.")
        return None

    # SAVE RESULTS
    json_path, csv_path = save_search_results(results)

    # DISPLAY
    display_search_results(results)

    print("\n‚úÖ Module 1 Completed Successfully!")
    print(f"‚û° JSON saved at: {json_path}")
    print(f"‚û° CSV saved at: {csv_path}")
    print("‚û° Proceed to Module 2 for downloading PDFs.")

    return results


main_search()

"""wFKolR3bfa5XUZaFntmdo5AXd7kL506y1klYRd3y

"""