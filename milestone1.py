# -*- coding: utf-8 -*-
"""Milestone1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18aGycrr1xBiA_poYHN-R42v3dcLsErHs

# MODULE 1: Topic Input & Paper Search (Milestone 1)
This notebook implements Semantic Scholar search, metadata saving, and result display.
"""

!pip install semanticscholar python-dotenv requests -q

import os
import json
from semanticscholar import SemanticScholar
from dotenv import load_dotenv

# ====================
# 1. SETUP API KEY
# ====================

def setup_api_key():
    load_dotenv()
    API_KEY = os.getenv("SEMANTIC_SCHOLAR_API_KEY")

    if not API_KEY:
        with open(".env","w") as f:
            f.write("SEMANTIC_SCHOLAR_API_KEY=LIh1hqt2wg8fh3a1q4ooK2ltZS5lJePH5Ydb66ew\n")
        load_dotenv()
        API_KEY = os.getenv("SEMANTIC_SCHOLAR_API_KEY")

    print("Semantic Scholar initialized with API key")
    return SemanticScholar(api_key=API_KEY)

# ====================
# 2. PAPER SEARCH
# ====================

def search_papers(topic, limit=20):
    print(f"\n Searching for papers on: '{topic}'")
    sch = setup_api_key()
    try:
        results = sch.search_paper(
            query=topic,
            limit=limit,
            fields=["paperId","title","abstract","year","authors","citationCount","openAccessPdf","url","venue"]
        )
        papers=[]
        for p in results:
            papers.append({
                "title": p.title,
                "authors": [a["name"] for a in p.authors] if p.authors else [],
                "year": p.year,
                "venue": p.venue,
                "citationCount": p.citationCount,
                "abstract": p.abstract,
                "url": p.url,
                "has_pdf": True if p.openAccessPdf else False,
                "pdf_url": p.openAccessPdf["url"] if p.openAccessPdf else None
            })
        return {"topic":topic,"papers":papers}
    except Exception as e:
        print("Error:",e)
        return None

# ====================
# 3. SAVE METADATA
# ====================

def save_search_results(data, filename=None):
    if not filename:
        safe_topic = "".join(c for c in data["topic"] if c.isalnum() or c==" ").replace(" ","_")
        filename = f"paper_search_results_{safe_topic}.json"
    os.makedirs("data/search_results", exist_ok=True)
    path = os.path.join("data/search_results", filename)
    with open(path,"w",encoding="utf-8") as f:
        json.dump(data,f,indent=4,ensure_ascii=False)
    print("Saved:",path)
    return path

# ====================
# 4. DISPLAY RESULTS
# ====================

def display_search_results(data, max_display=10):
    papers=data["papers"]
    print("\nResults for:",data["topic"])
    print("Total papers:",len(papers))
    print("PDF available:", sum(1 for p in papers if p["has_pdf"]))
    for i,p in enumerate(papers[:max_display]):
        print(f"\n{i+1}. {p['title']}")
        print(" Authors:",", ".join(p["authors"][:3]))
        print(" Year:",p["year"],"| Citations:",p["citationCount"])
        print(" PDF:", "Yes" if p["has_pdf"] else "No")

# ====================
# 5. MAIN SEARCH
# ====================

def main_search():
    topic = input("Enter topic: ")
    if not topic: topic="machine learning"
    data = search_papers(topic, limit=20)
    if data:
        save_path = save_search_results(data)
        display_search_results(data)
        print("Module 1 complete. Saved to:", save_path)
    return data