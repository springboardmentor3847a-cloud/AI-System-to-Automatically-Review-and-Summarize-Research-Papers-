# -*- coding: utf-8 -*-
"""milestone_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W7gnWZXfqIyA-QND6EoBNHu53NW65HoS

User enters topic
        ↓
API key is loaded
        ↓
Recent papers are searched
        ↓
Results are filtered by year
        ↓
Metadata is extracted
        ↓
Results saved as JSON
        ↓
Top papers displayed
        ↓
PDF downloaded and saved locally
"""

# ============================================
#  Topic Input & Paper Search
# ============================================
#INSTALL REQUIRING LAIBRARIES

!pip install semanticscholar python-dotenv requests -q

import json
import os
from datetime import datetime
from semanticscholar import SemanticScholar
from dotenv import load_dotenv

# ==========================
# 1. SETUP API KEY
# ==========================

def setup_api_key():
    """Loads Semantic Scholar API key from .env or creates file if missing."""

    load_dotenv()
    API_KEY = os.getenv("SEMANTIC_SCHOLAR_API_KEY")

    # If .env not present → create one
    if not API_KEY:
        with open(".env", "w") as f:
            f.write("SEMANTIC_SCHOLAR_API_KEY=LIh1hqt2wg8fh3a1q4ooK2ltZS5lJePH5Ydb66ew\n")
        load_dotenv()
        API_KEY = os.getenv("SEMANTIC_SCHOLAR_API_KEY")

    # Initialize Semantic Scholar client
    if API_KEY:
        sch = SemanticScholar(api_key=API_KEY)
        print(" Semantic Scholar initialized WITH API key.")
    else:
        sch = SemanticScholar()
        print(" Initialized WITHOUT API key (limited usage).")

    return sch



# ==========================
# 2. SEARCH RECENT PAPERS
# ==========================

def search_recent_papers(topic, years=2, limit=20):
    """
    Search for recent papers (last X years) on a topic.
    Returns structured dictionary of results.
    """

    print(f"\n Searching recent papers for topic: '{topic}'")
    print(f"   Limiting to last {years} years")

    sch = setup_api_key()
    current_year = datetime.now().year
    min_year = current_year - years

    try:
        # Search papers
        results = sch.search_paper(
            query=topic,
            limit=limit,
            fields=[
                "paperId", "title", "abstract", "year", "authors",
                "citationCount", "openAccessPdf", "url", "venue"
            ]
        )

        papers = []
        for paper in results:
            if paper.year and paper.year >= min_year:
                papers.append({
                    "title": paper.title,
                    "authors": [a["name"] for a in paper.authors] if paper.authors else [],
                    "year": paper.year,
                    "paperId": paper.paperId,
                    "abstract": (paper.abstract[:300] + "...")
                        if paper.abstract else "No abstract available",
                    "citationCount": paper.citationCount,
                    "venue": paper.venue if hasattr(paper, "venue") else None,
                    "url": paper.url,
                    "pdf_url": paper.openAccessPdf["url"] if paper.openAccessPdf else None,
                    "has_pdf": bool(paper.openAccessPdf)
                })

        pdf_count = sum(1 for p in papers if p["has_pdf"])

        print("\n Search complete!")
        print(f"   Total recent papers: {len(papers)}")
        print(f"   PDFs available: {pdf_count}")

        return {
            "topic": topic,
            "search_timestamp": datetime.now().isoformat(),
            "years_considered": years,
            "total_results": len(papers),
            "papers_with_pdf": pdf_count,
            "papers": papers
        }

    except Exception as e:
        print(f" ERROR: Could not fetch papers → {e}")
        return None



# ==========================
# 3. SAVE RESULTS AS JSON
# ==========================

def save_recent_results(data, filename=None):
    """Save recent paper search results into data/search_results folder."""

    if not filename:
        safe_topic = "".join(c for c in data["topic"] if c.isalnum() or c == " ").replace(" ", "_")
        filename = f"recent_papers_{safe_topic}.json"

    os.makedirs("data/search_results", exist_ok=True)
    filepath = os.path.join("data/search_results", filename)

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

    print(f" Results saved to: {filepath}")
    return filepath



# ==========================
# 4. DISPLAY RECENT PAPERS
# ==========================

def display_recent_results(data, max_display=10):
    """Pretty print top recent papers."""

    print(f"\n--- Top {max_display} Recent Papers for '{data['topic']}' ---")

    for i, paper in enumerate(data["papers"][:max_display]):
        print(f"\n{i+1}. Title: {paper['title']}")
        print(f"   Authors: {', '.join(paper['authors'])}")
        print(f"   Year: {paper['year']}")
        print(f"   Citations: {paper['citationCount']}")
        print(f"   Venue: {paper['venue']}")
        print(f"   Abstract: {paper['abstract']}")
        print(f"   URL: {paper['url']}")
        print(f"   PDF Available: {paper['has_pdf']}")

def display_recent_results(data, max_display=10):
    """Pretty print top recent papers in clean format."""

    print(f"\n--- Top {max_display} Recent Papers for '{data['topic']}' ---")

    for i, paper in enumerate(data["papers"][:max_display]):
        print(f"\n{i+1}. Title: {paper['title']}")
        print(f"   Authors: {', '.join(paper['authors']) if paper['authors'] else 'Unknown'}")
        print(f"   Year: {paper['year']}")
        print(f"   Citations: {paper['citationCount']}")
        print(f"   Venue: {paper['venue'] if paper['venue'] else 'Not available'}")
        print(f"   Abstract: {paper['abstract']}")
        print(f"   URL: {paper['url']}")
        print(f"   PDF Available: {paper['has_pdf']}")

data = search_recent_papers("AI research paper summarization", years=3, limit=25)
display_recent_results(data)
save_recent_results(data)

import requests

def download_pdf(pdf_url, title, download_folder="downloaded_pdfs"):
    """Downloads a PDF from a given URL."""

    if not pdf_url:
        print("No PDF URL provided.")
        return None

    os.makedirs(download_folder, exist_ok=True)
    safe_title = "".join(c for c in title if c.isalnum() or c == " ").replace(" ", "_")
    filepath = os.path.join(download_folder, f"{safe_title}.pdf")

    print(f"Downloading '{title}' from {pdf_url}...")
    try:
        response = requests.get(pdf_url, stream=True)
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)

        with open(filepath, 'wb') as pdf_file:
            for chunk in response.iter_content(chunk_size=8192):
                pdf_file.write(chunk)
        print(f"Successfully downloaded to: {filepath}")
        return filepath
    except requests.exceptions.RequestException as e:
        print(f"Error downloading PDF: {e}")
        return None

def user_download_one_pdf(data):
    """Allows the user to select and download one PDF from the search results."""

    papers_with_pdf = [p for p in data["papers"] if p["has_pdf"]]

    if not papers_with_pdf:
        print("No papers with downloadable PDFs found in the current results.")
        return

    print("\n--- Papers with Available PDFs ---")
    for i, paper in enumerate(papers_with_pdf):
        print(f"{i+1}. {paper['title']} (Year: {paper['year']})")

    while True:
        try:
            choice = input("Enter the number of the PDF to download (or 'q' to quit): ")
            if choice.lower() == 'q':
                print("Exiting PDF download.")
                return

            idx = int(choice) - 1
            if 0 <= idx < len(papers_with_pdf):
                selected_paper = papers_with_pdf[idx]
                download_pdf(selected_paper["pdf_url"], selected_paper["title"])
                return
            else:
                print("Invalid number. Please try again.")
        except ValueError:
            print("Invalid input. Please enter a number or 'q'.")

data = search_recent_papers("AI research paper summarization", years=3, limit=25)
display_recent_results(data)
user_download_one_pdf(data)
